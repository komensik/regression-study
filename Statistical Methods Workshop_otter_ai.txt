Speaker 1  0:00  
It, and then some of it will just be like new packages and functions. I think so. One is that this won't be on the mid term this week. I think Chris has always already made that quite clear. And so this is really just for just to learn. I'm not even sure it will be on the final because it's really technically complicated and so, and we're generally not going to be testing you your skills in R you're going to be just testing like interpretation and theoretical knowledge. And so today we'll kind of focus on like interpreting and like understanding what's going on. But don't worry if some of the technical stuff is kind of a bit challenging right now. Like, it's challenging for me, Chris. Like, there's huge debates in literature about, you know, the assumption coming through stuff and stuff like that. And so if it's something that you want to get to in your own work, like, then, you know, you'll probably become more of an expert in this over time, but for now, just like working these packages, you know you have the possibility of maybe working with it. You know that it's a resource available to you to be an offer now, okay, so for quiz seven, okay, so true or false in Gelman and Hill's approach, using the sim function estimation uncertainty in parameters is approximate variation in simulated parameter estimates. Is that true or false? True? Yeah, perfect. Any questions about that, we're going to be going through it like we'll use the function and, like the built in function, and we'll go through a little example of, like, what's going on underneath the hood too, today to kind of like, see how this actually plays out. But any questions before we ad there? Okay, well, next is, which I think is accomplished with re sampling from the data, with or without replacement. With replacement, yeah, so if you remember, like, this is something that we actually like started last semester, a little bit like some really basic booting with four loops, right when we were taking samples of I'm pretty sure it was like the age data that we were using and the sample size, because the sample size of the data set, but because we were sampling with replacement, it meant that we could get a different sample every single time. Okay, true or false, each graph approach can provide approximate standard errors or parameter estimates. Yes, that's like, probably the main use map is kind of to think about uncertainty. Wonderful. Consider the model with an interaction between x1 and x2 which of the following is true? We're looking for the marginal, partial effect of x2 so which one is it C? Yeah. And we can find that by just taking the partial derivative. And so we know in terms of like interpretation, we now know that the marginal effect of x2 is dependent on x1 dependent on the value of x1 you can no longer find it without plugging in a value there any questions on that? And then the last one, which of the following statements is true about model in question four. So this is another one about, how would we interpret beta three, or the interaction term? How would you interpret that

Speaker 1  3:48  
exactly. So it's just the change in marginal effect of x1 for a one unit increase in x2 you could also flip that. All of these are going to be like mirror images of each other, so it's the change in the marginal effect of x2 for a one unit increase in x1 Okay, any other, any questions on the quiz, move on. Okay, awesome, hopefully it wasn't too bad This week. Okay. Get into the lab.

Speaker 1  4:42  
I so basically, we're going to be looking at different ways of doing inference with non linearity, so ways of kind of understanding our uncertainty around our estimates when our. Um functions have, like, quadratic sort of interactions, right? And so just a familiar just a reminder of what we mean by quadratic and interaction. You all are really familiar with that. At this point, we're going to be going through three main, three main things with like a little extra so the analytical solution, which is actually something that we practice last semester in lab. So we'll go through that quite quickly. And you can always look back, I think it was like lab eight or something. Then simulation based approximations, and then we're going to go through boot strapping. And kind of like an example of boots, or it's like, kind of tangential to boot strapping would be Jack Knife estimates, which we'll do a little bit with as well. So it's just going to be like redoing a lot of the stuff that I think Chris went over and passed maybe with, like more of an opportunity to ask questions, go a little deeper, and then see it on different a different set of data that we're familiar with the HTML or the R and D bar, and are you going through the

Unknown Speaker  6:12  
error work for

Unknown Speaker  6:22  
secret, are you showing the dot R and D

Speaker 2  6:27  
and not the dot q and D? Yeah, it's fine. Okay,

Speaker 1  6:31  
cool. I I'm pretty sure, like I printed everything in the HTML. So you should wait. Okay, so we'll start with the analytic solution, which is what we went over last semester with, kind of the variance of linear combination as a way of approximating it. So we're working with conditional marginal effects. Again, just a quick reminder about what the quadratic marginal effect looks like and the interactive marginal effect. Are people feeling comfortable with interpreting what the marginal effect is at this point. Okay, cool. You know, we'll practice more of that today, but I think that's like, probably like, the most important thing from all of this, and something that you will be doing on the midterm, is just interpreting interactions, marginal effect, stuff like that. So I can answer more questions about that at the end. So what we're doing is we're finding the variance of this conditional marginal effect by using like the formula for linear combination, right? Because we know that that that effect is a linear combination of betas for coefficients, and so we're basically just plugging it into this formula here. I have the quadratic and interaction formulas, right? This is all review. So going really fast, but let me know if you need me to slow down and review anything. So to find the standard error of the conditional marginal effect, we're going to take the square root of that and basically I copied and wasted the example from the trees data that we did last semester. So if we're looking at an interaction between Earth and height on and how those affect the volume of the tree. I'm loading my data, I'm estimating the model. I'm creating a vector of height from minimum to maximum. This is stuff that we're all really familiar with, calculating the conditional marginal effect using the formula up here, this formula for the interaction, right? So I'm pulling the coefficients from the model, and then I am multiplying it by the range of height the beta three interactive term, and then I'll multiply right. And so this output is going to have the same number of observations that are in height, right? Because we're calculating a marginal effect for each value of height, right? We're going to extract the variance covariance matrix, because that's what we're using to plug into this equation for the variance of a linear combination, right? And then again, we're just plugging in, kind of be the variance, the range of height, etc, etc, to get the standard errors for this right, taking the square root of that. So this is the variance formula, and we're just taking the square root, and then I'm plotting this right across values of height, which will be on the x and then the conditional marginal, effective verb will be up the Y axis. And then I'm adding these confidence bounds, which I'm just adding, subtracting two times the conditional marginal or the standard error that we just calculated. Okay? So just going to run all this, right, so that we can see it. We're pretty familiar with this at this point, a quick reminder that this graph is looking. Act like on the left hand side is the effect, not an estimate for prediction of anything. So it's not like volume, right? It's not our output, but it's the effect of girth on volume and how that changes across heavy so we're kind of familiar with interactions at this point and what that means. Awesome. Okay, so, any questions? Yes, um, I just have a

Speaker 3  10:29  
question about when we're doing the class Canada for last week funding. So I had just adjusted at the bottom the next week. But then there was times where I would adjust to like, too close, I guess. So, like, you just take the same like, I you

Speaker 1  10:53  
talking about, like, if you set parameters before the plot? Yeah? So, um, yeah, you can just remove those. And I think it will, it will R will try to do it automatically, and then kind of space it for you. And then the limits that you're talking about is exactly right. Like, you can think about your limits of your axes beforehand by looking at the range of values you're interested in. So like, you know that you're plotting height, so you can look up the minimum and maximum of high income, and then make sure that the access covers that, and then the same thing for the marginal effect. Yeah. Any other questions about doing this manually or analytically and then manually flopping it? Okay, so Chris introduced the marginal effect package, which is what we're just going to practice with today. A couple different ways of doing it. So so the first two that I go through are basically, so this is doing exactly what we just did manually, right? But one of them is going to do it for every observation in the data. So it's going to use actual values of height from the data, whereas the second one is going to estimate it for the Ranger pipe, so it's going to do exactly what we just did, right? And then plot that. And then I'll show you some short cuts at the end, which we can just look these will get you the same exact answers. One of them is, is holding all variables at the means and then estimating the marginal effect. The other one is taking the marginal effect at every value and then averaging it, which you can see like you will get to the same answer either way, but we'll just go through these first so basically, it's within if you call your library marginal effects, right? Then we're going to be using the function slopes, and we're going to put in the model above, which is an interaction model in this case, and then the variable that you're interested in, right? And so if I run this, let me just call this. I then you'll see that this creates an object. You can open it up, right? And it's going to give you the estimate and the standard error at all of the values in the data set. It'll calculate those for you, right? And it's looking at the estimate of birth, which is what the term is telling you, right, yes, does the line of code drive opt in all the library? What is it doing? So that is something that is basically like Chris recommended that we use that is kind of so you can see that it's making sure that it doesn't print something I would have to, like look into exactly what that is, but it's just something that we don't any well.

Speaker 1  14:19  
So you can kind of see that this object is now basically a new data set, right? And then what we're doing down here is I'm plotting that. And so the difference between this plot and the plot that we just made is going to be that this uses actual values of height from your data set, whereas the one that we just made, we create our own range of height. Does that make sense? The only difference in what we're doing, okay. So then when I plot this, we can see, like, I mean, you can just see that it's like far fewer points here, because I don't know how many are in the data set, but not that many. Three and then they're going to be like multiple lines of standard error, because it's recalculating that for each observation. But they'll kind of converge, as you can see, on the same thing that would happen when you do it manually, and it smooths out for you, as well as when we do the next one over a range. It's the same thing, cool. But then you can kind of see that it creates the same, same, very similar graph to what we just saw, okay? And then I'm going to the same exact thing that we just did, so over a range, and the way that we do that is we're going to put in the model that we created. The variable that we're interested in is worth here, so I'm specifying that, and then I'm putting in new data. And this is setting height, which is like the name of the data in our model. So you need to make sure that that matches the name of the data in your model. And then this is the sequence that we created above right of values of height at point one increments from the minimum to the maximum. So when you see that, it's going to be 241 observations again. So you can kind of see that, like the me was 31 observations, because that was the number of observations in our data set. And so they were calculating the marginal effect for each value of height in the data set. But then when you move up to the C me that we just calculated, and all of these names are arbitrary, I was just trying to, like, meet different models so that we could compare them. Is 241 observations, because that's the number of values we get in our range of height. But it's going to be the same thing the term we're interested in, the estimate for it. The standard error at these different at these different ranges of height, and then I'm going to plot it, and it will look very, very similar. I'm just pulling the data from from the new data set that we created CME, and you can see that that's like plotting points, and so that's why it's such a big line. But okay, so any questions on kind of the plotting and doing exactly what we just did, but with a built in function now, the worst

Unknown Speaker  17:37  
difference between the

Speaker 1  17:42  
city and between? Oh, yeah. So basically, I called one of them marginal effect, because it's just calculating the marginal effect for each observation in the data, and then the other one I called conditional marginal effect because I'm they're both conditional. So I just needed, like, a slightly different name. And I thought, Okay, this is conditional on a range of height versus this one is the margin, marginal effect of different observations. But like, if I was doing this for like, if you were doing this for research, I'd recommend maybe naming one. Like, not that you would ever do this. You would choose one and just do one of one of them, because they're doing the exact same thing, you would maybe name it something like, you know, CME, G across height. Does that make sense? But they're doing the same thing, just with different data inputs. One of them has the like observation of heights, and the other one has the height that we created from the minimum to maximum. Yeah, great question. Any other questions about these plots before we go on to the other functions in marginal effects?

Speaker 1  19:02  
So now we have, like, a quicker, kind of a quicker thing, which is just, if we just wanted to know the marginal effect of each variable when the other variables are held at the mean. So this is the same thing as plugging and chugging. If you were like, Okay, what's the mean of height? What's the mean of birth? I'm going to put those into my my calculation for the marginal effect of Titan growth, you would get two values right, and that's exactly what this is going to do. It's just going to calculate those two values for you. This is going to do it like a little bit more tediously, by calculating the marginal effect for of each at every single observation of your data, as in plugging in the value of birth, plugging in the value of height, finding the marginal effect, printing all of those, and then it's going to take the average of all of them. But as you are about to see, they'll be exactly the same. So any. M we can see that these are our estimates and our standard errors, and so that is the marginal effect of birth when height is at its mean, and that is the marginal and then the second one is the marginal effect of height when birth is at its mean. Does that make sense? Yeah. So the top one is the marginal effect of birth when height is at its mean, right? And so we're plugging it into that equation. It's like beta one plus height, and we're plugging in the average value of height per height. Does that make sense? Yeah. Cool. And then the bottom one, we're plugging it into the other version of the equation for the marginal effect of height, right? Which is going to be beta two plus beta three times the mean or average birth. So basically, what it's doing is it just going to calculate the marginal effect at the average and that's it. But you cannot interpret these values without specifying the value of the other variable, right? You can't just say like the marginal effect of birth is 4.3 because it won't make any sense. We won't know. We don't have enough information. You have to say, marginal effect of birth at the average height is 4.3 Does that make sense? And that's how it goes with interpreting marginal effects all the time is like you just have to, if you want to give a value to your reader, you just have to specify the value of the variable it's dependent on, okay, cool. Okay, and then this is going to do the exact same thing, but in a more tedious manner. So it's me, M and mm. It's like the same thing, but it's just taking the marginal effect of every observation and then averaging them. Okay, so if we look at that, it's going to get we're going to see the same exact thing go. And then the last thing that we can do is a hypothesis test with the function hypotheses, right? So you just put your model in, and then you put the equation of your hypotheses. Here, we're basically looking at whether or not the effect of height and birth are the same, right? And then I think I probably actually should have scaled these for that to be meaningful, but there you have it, right? And so that's telling us, like the difference between the estimates and the standard error of that difference. So Okay, any questions about some of these things that we can do in marginal effects when it comes to this is all the analytical solution or technique, method, whatever you want to look at the p value as well. Yeah. So what is telling us? Yeah. So the p value is telling you the probability of finding an estimate that extreme. So the estimate here is the difference between the two. Yeah, right, yes, yeah. And so we wouldn't find an estimate that says they're that different, or this is the probability we would find that if the null hypothesis that They're the same is true,

Unknown Speaker  24:01  
any other questions about this?

Speaker 1  24:09  
So that wraps up the analytical so like analytical method of approximating standard errors. Does everyone just want to give a thumbs up if you're really confident about this. Thumbs in the middle, if you're like, I'm getting there, and then thumbs down if you're like, I have no idea what's going on. How's everyone doing? Okay, okay, okay, good. So any other questions, you know, and this will just like, come with repetition, right? But any other like clarifying questions before we move on to like, the next way of finding standard errors? Okay? It only gets more complicated from here. I. Let's go. Okay, so the next thing we're going to be doing is simulation based approximation. Great. Okay, and so generally, under the hood, what is going on, right, is that we're going to one simulate sigma, which is the error variance using the estimated sigma from our model, right? Because M, our model M spits out sigma, and we're assuming that it follows a chi square distribution. So we're going to randomly draw sigma from that distribution. I have that found here, by the way, as well. It's showing that are like the we're assuming that the predicted sigma squared follows this distribution. Then using that as our kind of like measure of uncertainty, we're then going to simulate beta for the coefficients, using both the estimated coefficients from the model as the mean, the simulated sigma as kind of putting uncertainty into them, into the simulation for us. And then also we're assuming a multi variant normal distribution, which is, I think, one of the more important things to think about when thinking about these different approaches, is like, what assumptions are being made, and so assuming a normal distribution is like, not always going to be accurate, right, especially with smaller sample sizes. So just something you want to be aware of and think critically about when using this technique, then we're going to use the distribution of the beta that we simulate to estimate the standard error, which is basically just going to be the standard deviation and the confidence intervals, which we're just going to use the quantiles of the distribution. Does that make sense, like what we're doing? Or does anyone have any questions about what, how we're simulating beta? Okay, so we'll go through the stack scene code, and maybe that will help a little bit. Okay, so the first one is, we're just pulling stuff from the model. So we're going to pull the estimated sigma, and that's just from the summary of m and we're going to do the same thing with the coefficients beta hat, and then we're going to also pull the variance, covariance matrix of beta estimates, because that's what we're going to be using. We're scaling it like according to sigma, is how we're putting the uncertainty in. Okay, then we have the number of observations, the number of parameters and the number of simulations that we want to run. Any questions up until here, I have a question

Unknown Speaker  28:07  
about, can you both remind one to me for the CO

Speaker 1  28:10  
matrix? Yes, so that's pulling out the unscaled variance covariance matrix.

Speaker 2  28:16  
And why is it? Sorry I put my confusion is, why is it unscaled? Yes,

Speaker 1  28:20  
because we're going to scale it with sigma, which you'll see very shortly, okay, but basically, that's where we're kind of, we're manipulating the uncertainty using the estimated sigma from the from the model, right? And that's why we're so we're basically going to scale it ourselves. Okay, yeah, cool. Okay, so then we're going to create two initialized arrays to store the sigmas that we simulate and the betas that we simulate, then we're going to run a for loop, right? So for from one to the number of simulations that we want, this is us simulating sigma. What we're doing is we're drawing a random value of sigma from the chi square distribution with n minus k degrees of freedom, right? So that's where this comes in. That is the random chi square distribution. Like it's the same thing as our norm. When we're taking a random draw from the normal distribution, we use our NORM. If we want to use the chi square, we're using R chi square, right cool. And then this is what we're we're basically multiplying sigma by this to draw a random variable from it. And this is this all comes from. This equation here, right? And so, so this is where it gets really complicated. Somebody else did a bunch of research and came up with this, right? And so that's why, like, and then this is where it gets like, really complicated for us to understand. I think at least it's like, where all the complication comes in is kind of like, why are we using a chi square distribution? And, like, why this and why, you know, why are we scaling it ourselves? And blah, blah, blah, blah. And you're welcome to go to Chris and talk to Chris about it, if you're, if you're interested, and if you're doing this later on in your work, but it's kind of beyond the scope of this class and very complicated, and that's kind of where we're picking up from. We're like, okay, so that research and told us that this works. So this is how we do it. You know, I think the other stuff we can, kind of, I can explain more, like, why we're doing all of this stuff, and then this is, like, at the edge of my understanding. So, okay, cool, so we're simulating sigma, yes, again the second line of

Speaker 4  31:07  
the code, how do we pull out the

Speaker 1  31:19  
estimated beta hat? Oh, oh, you mean this up here? Oh, yeah. So this is pulling it from the summary. M, so if you go to, well, this is, like, the model here that it's pulling from, but it's actually pulling from the summary of the model which has slightly different, it's a slightly different, like, has slightly different value within the object. But, like, let's look at some M, summary M, and then you can just take the summary of m here, right? And I can show you where it's coming from. So this is the summary, and then we're looking at the coefficients. So where is the summary? Here we go. So we're looking at the coefficients here, and then it's pulling out. So this is a four by four, because there are four coefficients, but it's giving you we're only looking at the at the first column, right? And then it's just having you drop anything that's not coming up. Oh no, yeah, that's beta hat. So it's just pulling out your coefficients from your model. And this would also work if you didn't want to use the summary, wait in previous code, we just use like the model, right? If you look at m here, it also has the coefficients here. So, but that's just a way of pulling the coefficients from the model. Yeah, so just another way of doing that in R, cool, amazing. So yes, can you say again about

Unknown Speaker  33:02  
what about why in the third step?

Speaker 1  33:07  
Yes, so the loss of staff, we scale it. We're scaling it ourselves is basically so generally, like, if you see here, like, okay, the two that we can look at are kind of, this is where we're pulling the unscaled and then this is where we're scaling it. So we're scaling it by sigma square. And so we're using the unscaled here,

Unknown Speaker  33:39  
standardized order.

Speaker 1  33:42  
So that's what if we have pulled the scale it would have been standardized. But we want to scale it fire by our sigma that we're manipulating, because it would scale it by the sigma dot hat, and we want to scale it by the sigma that we're manipulating. Does that make sense? So up here we have this sigma hat at the top right, and that's the what the model is estimating sigma is. And so it would scale it based on that sigma. But we want to manipulate sigma, because we're pulling sigma, our own sigma from this distribution right here. So if we had gotten the scale version, it would have been scaled according to their estimate, but we want to scale it according to our estimate, and that's the difference between sigma dot hat, which is the model estimated, and sigma i, which is our random draw of sigma from the Chi. It's chi distribution.

Speaker 4  34:53  
Can you explain what is the first one mean and what is the second one? SW of the distribution, the distribution like, what is the mean of the distribution? I mean, the center

Unknown Speaker  35:10  
of the chi square distribution, no, of

Unknown Speaker  35:13  
the scale one versus the on scale one?

Speaker 1  35:16  
Oh, I'm not sure. I'd have to look, let me see. So what we could just do is one minute.

Speaker 1  35:34  
And so this is the unscaled, right. And so it's looking at kind of the intercept and then, or the so this would be variance along the diagonal you can see down there. And then the covariance is on the off right, and then we can just compare it. And it doesn't if it's called scaled, but let's just see it might just be called covariance, or V Co. There we go. Is it very different? Looks identical here. That seems wrong.

Unknown Speaker  36:18  
So this is the summary of m. So we're going to go back to summary. Oh, so maybe it only has unscaled,

Speaker 1  36:34  
huh, okay, so maybe it's always unscaled, and that's just the name of it in summary versus in the model.

Speaker 1  36:53  
Yeah, okay, so I guess I'm not sure if there's a way that you can scale it. I've never tried before, but you're welcome to talk to Chris about it if you want to know or, like, look it up. But for now, I guess it's just important for us to know that we're scaling it ourselves. Does that make sense, according to our manipulated version of sigma? Awesome. Okay, so we have everything that we need. Okay, so we've just simulated sigma according to the distribution above this distribution right here. So this line is just plugging this formula in right and the randomization is coming from the chi square distribution, right? Which is this random chi squared? Okay, then we're going to use that sigma that we simulate i times, right? So each of the 1000 simulations would have a different sigma from this distribution, right? And we're going to estimate beta. And the way that we're doing that is we're pulling it from a multivariate normal distribution, right, where beta hat is our mean, and then we are scaling the variance covariance to to this sigma squared value, and

Speaker 1  38:39  
then we're going to draw a random values from that. And basically what this is doing, which, again, you will probably never do this, because there is a function that does it for us. But just to give you an idea of what's going on underneath the can function so that we have, like, an intuitive understanding of it, which is like this list of things right here. Okay, so if I run all of this, we're going to get an output of betas right, and we'll see that come up here, right? So we have four coefficients, and we're estimating each of them 1000 times, or not estimating them, we are simulating them 1000 times, right? And so basically, like, what we can do with this is, then we have this data set of betas 1000 and we can take, like, we can use the standard deviation of it, or the quantiles of it, to get our standard error and our confidence intervals right. So it's giving us a distribution, and then we can, like, run different summary statistics to then get our quantities of interest. Okay. Right? So this is all under the hood of this package, which is going to simulate it for us, right? And so again, intuition is just we're simulating sigma, assuming that it has a chi square distribution around the estimate that the model provides you. And then we're going to simulate beta by using the by assuming that it's centered on, again, estimates that the model gives you, but then we're manipulating the uncertainty, or like putting an uncertainty into this simulation with the simulated sigma that we're pulling from the random chi square distribution, and then we are assuming that beta is on a multi area environment distribution, okay? And then we're going to use that distribution that results, and that's where we're going to find our like standard deviation and our quantiles and things like that. Okay? So to do this in a package, we're going to be using Sim from the arm package, right? And it's really as simple as putting in your model and then telling it the number of simulations you want to do.

Unknown Speaker  41:20  
And it's going to do basically everything in that last co chunk under the hood, right? So now we have an n Sims, which will just tell you, there's the coefficients, and then the sigmas. So

Speaker 1  41:38  
then you can look at the coefficients, you can just look ahead of them, right? And there will be 1000 of each of each of them, if that's what you specified here. And then you can also look at the sigmas that I used. Yes, so arm is the package and sim is the function, yeah, and so that's this notation right here, like, anytime you're using, like a double, whatever that thing is called, two dots, that's saying that the first thing is the package and the second thing is the function. Did you install packages arm? Yeah, so install arm, and then it'll be able to run sim from that. Nice, awesome. Okay, so then we're going to use this here to So, thus far, like we, I kind of just did an example of, like, all of these different betas, right? But what this is doing for us is it's calculating, just like beta one, beta two, beta three, which is our which are two constituent terms and then our interaction term, right? So if we wanted to look at the conditional marginal effect again, bringing it back to that like interaction, right, we're going to be applying across the values, across the coefficients, right? And this tells us that it's the rows. Rows is one and columns is two. So across the rows of the coefficients, we're going to be applying the function that is the conditional marginal effect function. So this should be really familiar, right? So, like, the x that it's putting in is the coefficient from the from this like simulation function, right? So it's calculated a bunch of coefficients. It's going to use those coefficients, that's going to be our x, right? And it's going to say, okay, apply the coefficient of birth, and then add the coefficient on the interaction term multiplied by, again, this range of height that we used originally. So we're familiar with that already, and that's going to give us the conditional marginal effect using simulations, right? And then this is basically just applying. So this is the same thing that you would do, even if you did it manually, right? Manually, you now have a sigma and a beta, whereas here you just have it in a built in function, right? But you're coming out with the beta and the sigma anyway. And so these are the different things that you could do with it to like, find uncertainty, right, specify your uncertainty or your due inference, right? You're going to be finding the standard error, which is just applying standard deviation, and then for the lower and upper confidence bounds, we're going to. Be using the quantile function, yes.

Unknown Speaker  45:02  
So for the for the arm package, uncertainty

Unknown Speaker  45:04  
comes from the first step, right?

Speaker 1  45:10  
So with the arm package, it's everything is going on under the hood is in the previous one, right? And so the uncertainty is coming from, actually, do you want to repeat your question? I think I'm answering the wrong

Unknown Speaker  45:27  
question, Where does the Deo simul

Speaker 1  45:29  
like the uncertainty that we're calculating? Or how do we put uncertainty into the simulation we're calculating for each of the correlation? Yes, so our uncertainty is basically standard errors, right? And so we're finding the standard errors. We're approximating it using standard deviation, and then we're approximating our lower and upper confidence intervals using the quantiles. And the reason that we can do this right is because we saw in the under the hood section, we're assuming a normal, a multi variate normal distribution of beta. And so that's why we're using the standard deviation and then the quant files.

Speaker 1  46:22  
Yes, so this for loop up here is doing what the package does, what? So this package, right, is doing this? Yeah, does that make sense? So, so, because we're what we're giving to the package is the model and the number of simulations. And so the package is saying, OK, let me look at your model. I'm going to pull out the sigma, I'm going to pull out the coefficients, and I'm going to pull out the covariance, variance, covariance matrix, the N, the K, and you've told me the number of simulations you want. And so it has all of this information accessible to it, and then this is what it's doing with that information, right? It's pulling the sigma from the chi square distribution, and then it's pulling the beta from the MVR norm, yep. And then it's filling in these arrays, right, the sigma and the beta. Now we did that all manually, but what you going to get when you run MCs. You can see here is just a coefficient matrix and the sigma vector, and that's exactly what you did manually above. Does that make sense? How the outputs of our store loop, of our for loop, are sigma and beta. And the outputs of this function are also sigma and beta,

Speaker 1  47:51  
exactly. So we basically, I wanted to show, well, Chris wanted you to see, so that's what's happening underneath. And I do think it's helpful to know, like, this is how we're getting sigma. This is how we're getting beta. Helps a little bit with the intuition of what's going on. But at the end of the day, this does all of that without

Speaker 1  48:21  
you know, I am not gonna lie, I am on Chris' side in terms of, I think it's really helpful to, like, have it available. I just don't want you all beating yourselves up about understanding, like, every little bit of it, because Chris and I don't understand every little bit of it. This gets, like, super complicated. People study this for their entire career, so, but these are really helpful tools for us, as long as we understand a little bit of what's going on with them. Okay, so we know that the simulation package in the arm, or the simulation function in the arm package, is simulating sigma on a chi square distribution, then using that sigma and assuming normal distribution, simulating theta. And then we're using those simulated outputs, which are in coefficient and sigma. We're using those to estimate our uncertainty, which we're just doing with standard deviation and quant files, which we're pretty familiar with, okay? And then we can also obviously calculate the conditional marginal effect here as well, using the formula that we're really familiar with, and that's just applying it over all of the simulations. That's how we're using a plot here. Okay, any questions about simulations? I think we're doing okay on time. Okay, so next we're doing a little bit of a like a side note on Jack length thing. I. Which is very similar to boot strapping, but where boot strapping is taking a sample with replacement from the your observations, Jack link is just removing one observation each time, and then we're going to, we have this very helpful like, this is the equation of the variance of a jack knife, and so we're basically taking the square root of that,

Unknown Speaker  50:33  
and that is Our standard error. Okay, so let's go through this. We have the sample size and the number of parameters, again,

Speaker 1  50:50  
with n and k, and then we're going to create an empty array to store our coefficients, right? So it's going to have all na as the inputs, and it's going to be the number of coefficients, K, by the sample size, n, right? Okay, then this is just removing the observation and re estimating the coefficient. So it's saying, for i in one through the number of rows of the model. So it's saying, repeat this for like, the full length of the data, right, which is our n here. I think, I suppose I could have just put n in there. I don't know why I repeated it. But anyway, we're going to take the betas, right? So we're going to pull the coefficients from the updated model. And the way that we're updating the model is we're just removing the observation. So that's where the negative sign is coming in, and I it's in the row subset, right? So it's saying, like, negative, I just remove the I row of the data, and this is the data from the the original model, right? And then this the dots, is just saying, like, stay the same. I think you all have seen that before, because we did it for like, the F stack and like, re estimating the model, the same model, but with the restricted data right. We used a similar thing to update the model, saying, like, we want all of the same variables, we just want the data to be slightly different in that we're removing the height row, right? So we're going to repeat that for the number. So we're going to get the same number of observations. That's the number of unique samples we're going to get right, because each time we remove one observation, that's a new sample. So we're going to do that that many times, and then we're going to put all of those coefficients into the I column.

Speaker 5  53:02  
Okay, so So

Speaker 1  53:05  
there's going to be k rows, so the rows are going to be our coefficients, and n columns, n is going to be the simulations, okay? And then intuition wise, we just need to know that we are removing the i th row from the data and re estimating the coefficients using our model.

Unknown Speaker  53:34  
Cool. Okay,

Speaker 1  53:38  
so then we're just going to take the mean of the rows, right, because each row is 1000 estimates of that coefficient, and that's going to give us our average beta. Cool, now this is doing now this and this right here, both of these, yes, so this is how to do it with matrix multiplication, basically matrix stuff. And this is how to do it by just plugging and shrugging the formula. And both of them are this formula right here, right so in this one, we are basically summing the outer products, element wise. So like each element of the matrices, right? And we're doing this across a list. Now, you can't just use apply, because we're working with matrices, so we need to use L apply, right? We're going to do this across all of the different all. Observation slash like all of the times that we ran the simulation, which is equal to the number of simulations, and we're basically going to be subtracting the betas that we like, estimate, estimate from the mean. Right? We're taking the transpose of that and multiplying them right, matrix multiplication, and then summing them element wise across all of the different matrix matrices that are coming going to be created, like basically I matrices, right, or n matrices, because you're doing this, I one through n right? You're going to do this for every simulation, right? That's where the I is coming in, right? So you're going to take the estimated betas from your from, or, I shouldn't say the word simulation from, oh no, simulation. I guess it's still a simulation. Okay? So each so basically, each time you do this, you're going to estimate the betas, and then you're going to find the difference from your average calculation, right? You're going to take the transpose and multiply it, and then for each simulation you do, which is going to be n, you're going to get a matrix there, and we're summing them all element wise. So that's how we're getting the sum of the outer products, right? And we're basically just using that. We're multiplying it by n minus one over n in this equation up here to get the jack knife variance. Okay, so that's one way to do it, matrix multiplication. The other way to do it is this line right here, which is just applying across the betas, right? This is, is me, just like, this is just the translation of

Unknown Speaker  56:59  
this up here. Okay, so just two different ways to do the same thing.

Speaker 1  57:07  
So I have one of them here. Is the jack knife and Jack Knife variance. Maybe I should have done like Jack Knife and the jack knife and for matrices. So you're taking the square root of the variance here, because, again, we're getting the the matrix. So we're taking the square root of the diagonal, and then, whereas here we're just like, calculating it ourselves, and then we have the other way to do it, is with OLS. So OLS is going to come up with its own V C, O, V M, and then this is doing it with heteroscedasticity, robust standard errors from the sandwich package, which I think we will use the sandwich package later. So don't worry about that. Now about specifics of how to use it, but again, I think Chris just wanted us to be able to compare these in class, and so that we go over it here, so you can see that the two ways of doing Jack Knife are identical. Obviously, one of them is just using matrix operations, and the other one is using like not matrix algebra, I suppose. And then OLS is going to get like the wonkiest, I guess, so

Speaker 1  58:40  
far off, I guess it makes sense that like OLS isn't going to work out in this context because of the low sample size and then The robust heteroscedasticity robust and repairs there.

Unknown Speaker  58:58  
Okay, so

Speaker 1  59:05  
that is Jack Knight. Okay, so we have about 15 minutes to go through boot scrapping, which I don't really give us enough time. I know that this is like a lot to throw at you, any questions up until this point, and I think, like, we can focus on high level like so these are all just ways to get different approximate or different estimates of beta and then use that distribution that we get from estimating beta so many times, we can use that distribution to estimate uncertainty with, like, really simple descriptive statistics, like standard deviation and quant files and things like that. And we're going to be going back to the same thing for boot scrapping is like, we can use some of these, like really basic functions once we have that distribution of beta. Yeah.

Unknown Speaker  1:00:03  
Any questions.

Speaker 1  1:00:13  
So for boot strapping, we're basically this is probably what you're also familiar with. I'm pretty sure we did this last semester as well, at re sampling from our original data to get, again, another distribution of the parameters of the coefficients, and then using that to estimate uncertainty. I do people see the difference between like boot strapping and simulating? No anyone want to give it a go. Bootstrapping is taking

Speaker 2  1:00:58  
data that be a small, sample pot of data that we already have and using it to re sample, to get the standard errors. Then simulation is when we we have data, but we don't wait, we have a small pot of data, and we don't know that there, we're trying to get the variation of the small pot of data, and so we're sampling more, so you figure out what the variation actually

Speaker 1  1:01:27  
is. Yeah, really close. So both of them we're looking for, like the variation, and we're looking for the standard error. We're looking for, like, lots of different measures of uncertainty. But with bootstrapping, you're exactly right. We're sampling from the data that we already have exactly. With simulation, we're using the model estimates to simulate new data exactly. So we're not sampling, we're simulating. And so like we went over how to do that earlier, like what we're using from our model to simulate that data. But it's kind of the difference between like, what we have had you doing it in the lab. In the last couple labs, we've had you like, simulate data where you like, have a model, and then you use that, and you multiply that by like, your you like, you basically assume some distributions of your x's and your errors, and then you use that to estimate or to simulate y, right? So, like, in one of them, you're simulating. Why? Whereas, like, it's the difference between like, creating something that doesn't exist, and sampling from something that already does. And so like we've done some of that simulating already, but then what we would do with that simulation is we would calculate or estimate beta with it over and over again, which is exactly what we're doing here, whereas now we're using the data that we already have and then estimating data again and again. But at the end of the day, it's basically just where is this data coming from. We need data to be able to estimate the coefficients over and over and over again, and in order to do that, we either need to simulate data or we need to re sample from our from our sample.

Speaker 4  1:03:24  
I just want to ask if simulation is based on our understanding of the distribution of the data, which should not necessarily exist, and boots driving is like we're trying to read something from our data set. That's the solution. Actually give us more accurate answer

Speaker 1  1:03:44  
yes. So well, it's a huge debate in treated Yes, but I would say yes, absolutely and, and I think Chris would agree with this. So basically, boot strapping, I think is a little bit it's not quite outdated yet, because it's still new, but I think people have realized the problems with bootstrapping and, like, the assumptions that need to be made for it to work. And so, like, it's used for small sample size, but it's especially inaccurate on small sample sizes. And then I'll go through a couple different ways, like, so we'll go through, like, normal boot strapping, like classic boot strapping. But then there are a couple of different things that you can use here, right? So one of them assumes the normal distribution. But then we also have percentile intervals, which just assumes asymptotic symmetry. And like not necessarily normal, there's bias corrected, accelerated by is corrected, and then percentile T, which uses the student t distribution. And so like this is another thing that like again, is has a huge literature that you kind of dig into on what you might want to use in your own research. And there's pros and cons to all of them. Them, but it seems like just plain old boot strapping is really no longer kind of trusted as trust in the method. Okay, so

Speaker 1  1:05:17  
to simulate new data exactly, so we're using the estimates of sigma and the estimates of the coefficients to simulate more coefficients.

Speaker 1  1:05:39  
Okay, and then bootstrapping, we're pulling from stuff that's already there. OK, so the boot strapping this I really certainly also did in lab last semester, so you can look back to that as well, like very simple versions once we so basically, we're going to get a distribution of estimates, and then we're going to take the square root of the sample variance, that's going to be our S, E, and then, and then, kind of what we mentioned before is that it seems like the boot strapping is actually inconsistent with non linear functions. And so as an alternative trim, we can trim the most extreme percent, P percent of bootstrap estimates before we calculate the standard error. But then we also have some alternative strategies below. Okay, so we're going to have the number of bootstrap samples, and then the number of regression coefficients, including the intercept. So just a plus one, we're going to initialize an array to store the coefficients. So it's the same thing that we've been doing with like an empty array with the number of rows being the number of simulations, and then the number of columns is your coefficient. So when you look at this matrix at the end, you're going to be able to see each column is a different coefficient, and then each row is a different simulation, right? And so instead of earlier we did this, we oriented so that it was the coefficients were on the rows, and the simulations were on the columns. And so we took the means of the rows, but now that we have it switch, we're going to be taking the means of the columns, right? So you just need to be cognizant of that you want to make sure you're taking the average of of what you want to be taking the coverage out. Okay? So then we're just going to iterate over the samples. So we're going to create new data, right, which is just sampling from one into the number of rows in your model, in your original data, right? You're going to be sampling that much from it, which, again, is just your sample size, again, with replacement. So that's the replace equals true. And we went through all of this last semester as well. So hopefully this is slightly familiar to us, but we're going to be sampling from one to the number of rows in the model, we're going to be sampling the number of rows, so whatever the number of observations is, with a twist zone, then we're going to basically run the model with the new data and pull the coefficients From it, right? So this is our formula from the model, and the data is the new sample. So

Speaker 1  1:08:52  
that's going to subset this the data based on that you

Unknown Speaker  1:08:58  
hold here, hey, and then we're going to put that into our array. Okay, then to calculate the standard error, we're just going to

Speaker 1  1:09:12  
like across the array. We're just going to or across the columns of the array, we're just going to take the standard deviation right and each column is 1000 estimates of the coefficient, because we said 1000 boots, so 1000 estimates of the coefficient. You're just taking the standard deviation of that of those estimates. So you'll get a different one for each coefficient, okay? And then this is how you trim it. So basically, you're doing the same thing you're applying across the the columns of your matrices, right? But then I've included this function right, that is going to trim. Trim each row so that it only is taking the values that are greater than the bottom one percentile and lower than the 99 percentile. So I'm just trimming off the bottom 1% and the lower than that upper 1% right? And then you can change this, like, I put point 01 and point nine. Nine. You could change it to point one and point nine if you wanted to trim, like, 20% of the estimates for most extreme estimates, and then you're just going to return the standard deviation of the trimmed data. So yeah, so that's just trimming, trimming it. And we could find, like, at least in marginal effects, like a built in function for trimming, but we'll definitely let you know if we find, like, a built in function for doing this. And then you can see they're quite, they're quite, I mean, like they're quite similar, I would say. And so that's just looking at the standard error for the boot strap estimates, and then the trim boot strap estimates, standard errors.

Speaker 1  1:11:21  
Okay, so last little bit with, Okay, last little bit with the last three minutes that we have for finding confidence intervals. There are all of these different ways of doing it right, which I believe you talked about in class, or maybe you haven't gotten to it yet, but it's definitely in the slides. And so I'm sure Chris will get to it eventually, about these different kind of types of boot strapping that you can do based on the assumptions that you feel comfortable making, right? And then we can use the marginal effects package again, and then the input rate. What we're going to be, the function we're going to be using, is inferences, but the input of that is the marginal effects object. And so what you'll want to do is, you'll want to run the marginal effects first. So here I'm looking at the marginal effects of both height and birth, at the mean of both variables, right? And then here I'm saying I want to look at the mean mark, the marginal effect of the means, right, using the method bootstrapping with this number of simulations. And then this is what tells you the confidence type. So this would would be with the percentile intervals, whereas BCA would be bias correct it, and then I can show you, maybe down below, I show you that you'll be able to kind of see all of them anyway, right? That's like the normal, the basic, the student that will be the percentile T, the percentile is just the normal percentile one. And then the bias corrected is ECA. So up here, if I just run these, and they'll take a while because it's 1000 it's running 1000 times. So you just have to be a little bit patient. But what this will come up with for us, like the output will have the estimate, the standard error, and then the confidence intervals that we've asked for on both birth and point. So this is the marginal effect of each at the mean of the other. Okay, so that was using marginal effects, which, like has, I think marginal effects just runs boots through it, like it calls the boots package. But if so, if you wanted to do it directly with boot package, this is how you do it with this. So you're just going to have your model. The this is running the data on the on a random, random row in sees. So it's basically just sampling the data like we did by hand. Above, you're going to be refitting the the model on that new data. So then you'll take a coefficient from it. We're interested in the fourth coefficient, right, because that's our interaction. And then this is taking the square root of the diagonal of the variance covariance matrix. So it's basically taking the square root of the of the variance of each of these distributions, right? And then we can return the beta and standard error, right? But then I think this is maybe even a little bit less complicated, right? And so you can kind of see, using boots, it's going to give you the confidence intervals at all with the. Different I specified here that I want the CI you can see this, and so it's going to give you all the different types of confidence intervals. So that's just kind of like a really like rushed overview of all the different bootstrapping and simulation methods. And then just, you know, a reminder that all of this is to, like, think about the uncertainty in your model. So think about, like, when I have these coefficients, whether or not it's a linear combination of coefficients as in the marginal effect, or if it's like in a standard model, if it's just a constituent coefficient. This is helping us look at different ways of either simulating beta or re sampling to re estimate beta on different samples as a way of getting a distribution of our coefficients that we can then take simple summary statistics like standard deviation of to think about our uncertainty or quantiles when it comes to confidence intervals. So all we're doing is like calculating standard error and confidence intervals in different ways cool, and it could be really helpful for, like, smaller data, right? And and, like, the non linear stuff that we we generally rely on, we, you know, we've relied thus far on this, like, analytical way of looking at it. But another way to do it is, is this way cool? I any questions? Okay, I haven't even seen the problem set that Chris wrote for this, but I have office hours on Tuesday as usual, and you're welcome to come for just like mid term questions as well for that. So,

Speaker 1  1:17:14  
I don't know, I checked on the so is that after spring break? Thursday, after spring, right? Oh, there you go.

Speaker 1  1:17:30  
Yeah. So last Tuesday, you'll have office hours that you can come to for questions on the mid term, or questions on this, I would focus on the mid term and then take the mid term on Thursday, then you'll have another set of office hours. We I don't think we'll do lab next week. I'll track with Chris, but really,

Speaker 1  1:17:58  
no, that's great. I'll take a day off. Okay? So no lab next week, so then you'll have the office hours after coming back from spring break that you can ask about the problem set. Then if you want to put it off until after the

Speaker 5  1:18:15  
defer. Okay, yeah. Regression

Speaker 5  1:18:33  
I you so

Unknown Speaker  1:18:49  
what this will probably do is like, I

Transcribed by https://otter.ai
