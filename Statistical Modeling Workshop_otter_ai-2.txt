Speaker 1  0:00  
You don't want to use it like in isolation, would be that you also want to look at, like, the different kind of the coefficients in your model and the standard errors, and you're going to want to use it in combination with all the other information you have, as well as, like, some theoretical and substantive knowledge to kind of to actually make those kinds of decisions, rather than just the r squared. Does that answer your question? Yeah, okay, cool. Any other questions on this one? I think that's a good one. Like, it's, it's good to think of r squared as, as, not necessarily, like, you know, testing but, but giving you more information on this goodness of fit and allowing you to compare. Okay, any other questions on the quiz before we move on to problem set? Okay,

Speaker 1  1:02  
I can't see all of your screens, by the way, because I'm sharing my screen. And so if you do have a question or something, and you and you like actually wave or react, I think will allow me to like, your screen will come up if you do that. Okay, so, or you can just turn off your mic and and yell at me, and I'll hear that too.

Unknown Speaker  1:23  
Okay, so let's go into our studio now. Okay, so just move where you all are so I can see.

Speaker 1  1:39  
Okay, so first quick little thing that I wanted to go over that I had questions about was that you have started to be asked to write formulas in R markdown. And so I thought I would just go over a little bit on on how to do that. Obviously, you can look back through like the labs to see how I've written the formulas in our mark down and pull from there, but just some, like, general rules and guidelines, I would say that mark down is like, completely a combination of backslashes, underscores and curly brackets. And so if you don't want to look something up, like, just try those things in succession, and you'll figure out what, what works and like. And then as you start using it more often, you'll get used to to to kind of like, which, which formatting you need. And so backslashes are generally used to create like symbols. So, so if you wanted to put a hat on something that would be backslash hat, if you wanted to write beta, the symbol beta into your formula. It's a backslash beta. Delta is the same thing. Backslash Delta, a lower case delta is going to give you that partial derivative, like the curly d. And then the upper case delta is going to give you the triangle, if you wanted to put a bar on top of beta, instead of the hat, that's going to be backslash bar. And then finally, fraction also uses backslash fraction. And then we'll see down there that you're going to use curly brackets to kind of denote what's in the numerator versus what's in the denominator. And then these curly brackets also allow you to nest things. So the example here is, I'm putting a hat on beta one. We'll go through underscores as well, but you can kind of see this com This combines like everything that I'm talking about, in terms of, we've got the back slash hat. We're nesting that. We're nesting like beta one inside that hat with these curly brackets. And then we're using an underscore one to put in a subscript. So then the second note that I have is that underscores are used to create subscripts. And then in the next one, we're talking about curly brackets. And so curly brackets will allow you to put two things into a subscript. So if I just put beta underscore one, I one would be subscripted, and I wouldn't be. And so putting the curly brackets around it allows you to subscript both. And then finally, yeah, curly brackets, in general, just either nest things or keep things together. And so with a fraction, we're kind of denoting what we want over in the numerator, and then what we want one underneath the fraction in the denominator. And so we're kind of using all the same things. And then I've used delta here as well to show you kind of a partial derivative, yeah. And so feel free to mess around with those things. They're all also things that you can look up. When looking them up, I would say things like, you know, like, you can say things like, how to add the hat to the beta, but I would just say in our mark down. And then if you put that those keywords are mark down in it, then it will kind of, or just mark down in general, because this also works for like late tech and other and over leaf and like other programs that use the same mark down formatting, then you'll be able to look these things up. Okay, any questions about mark down formulas?

Unknown Speaker  5:09  
Okay, awesome.

Speaker 1  5:12  
Okay, so the first thing we're going to do is review log interpretation from last week. So we're going to use the same CEO salaries data set. I checked with Chris about this, and I think in general, he would like you to use the precise calculation. But I think for Developing Intuition, it's also really helpful to have the approximation. And so basically, for the next three models, the log level, level, log and log, log, I basically put both the equation for the precise interpretation and the approximation, so that you can kind of look at the two and compare them. And if you want to play with this on your own, you can see how like changing your unit change or percent change will affect like how close the approximation is to the precise interpretation, which I think can be helpful for just developing an intuition for this stuff. But then generally, the approximation will be good enough for most of us when looking, when like reading papers and things like that. Okay, so I am just going to load in salary. I'm logging salary and profit so that we have this L profits and l salary variable to use when we need when we need it. We're going to start with the log level model, because you all are already really familiar with level level models, and so we already kind of went over this in the last lab, and then I think, oh, and Chris mentioned that in class, you all went through kind of, like the proof, or like the calculus of kind of how to get from like this model to like how to precisely interpret the coefficient. And so we don't need to go through that again here, but just practicing like how to interpret these things. Yeah, Tom, be question, you are muted, so you might need to unmute. Sorry. Great for me. I think, I don't think that the profits have been logged in what you just did based on how many variables there are, because there are negative profits, yes, so that's something that we went over last week. Basically, because there are negative profits, some of them will produce NAS, so that's exactly right. And a really good thing to think about when you're transforming variables like this is, are you going to lose any data for profits? We will be losing negatives. And that's okay, because we're just doing this to kind of as like an example. And so here R has just input. Na is for those values. Okay, sorry, I think this I made a mistake, because it's not running the code for me, but that's fine. I thought that maybe it just hadn't run for you either, and so you wouldn't be able to do things. But I think that it has. And the issue is I've done something wrong. Yeah, it's probably just, like, a parenthesis or something. I'll figure, yeah, feel free to stick around at the end of lab, and if you want to share your screen, and we can go through it to see what's going on. But yeah, we should be able to log both of these things and then salary. You won't. I believe there's, yeah, there's, like, no negative salaries, and so we won't lose any information with that, but we will lose some stuff with profits the other Yeah, okay, so we've transformed these variables. Great. Note, there any other questions about just transforming variables logging? I um, okay, this should be familiar with us for like, the sub setting and things like that. Okay, so now we have our log level model, and so we're interested in logging our dependent variable with a level or not logged independent variable. And so in this I've written the general formula here I maybe should have written in that y is our outcome is salary, and our our independent variable is profits. But you can see that down here with our model. And then we know from last week that the precise interpretation of this is that a one unit change in x1, which in this case is profits. And we know that profits is in millions, right? So a $1 million change in profits is associated with this calculation, percent change in y, which is our salary, right? And so we're basically taking E to our coefficient times the change in x. So if we're interested in a, like, one unit change in x, I should maybe have like delta here, delta unit change, because it really just depends on, like, whatever change you're interested in. We're subtracting one from that and multiplying it by 100 and that's just to change it into percent as well. So I know that we worked with like factor changes last week, and I figured that most of the time you're going to be you're going to be looking at this in percent changes. And so just to kind of try and simplify that for you, like I've just focused on on percentage here, but if you look back, you can see that like it's very closely related, right? And just two ways of saying the same thing. Okay? So I kind of, I look at how we do that here from last week, we also know that we need to be super careful with the parentheses, right? So we know from this equation that we want like the exponentiated or like e to the beta minus one to be in parentheses, and then multiply that by 100 and that will get us our precise interpretation of this coefficient in terms of what a one unit change in or a $1 million change in profits will do to salary. And so let me just run this so we can see here that our coefficient is point 00059, right. And so it changes ever so slightly to like to a 5946 as opposed to 5944 but is very, very similar to this approximation, which is just multiplying 100 by the coefficient. So if we do that here, we can see, see the change there. So very, very slight. Something that affects this is that we're looking at a one unit change. And so this, the approximation is going to be less accurate, as we talk about like greater changes in x. And so to stay on the safe side, you can just always use the precise approximation, or the, sorry, the precise calculation. And then when you're using when you're looking at a one unit change, it might be safer to use the approximation. And when you're like reading, I think when this comes up most is when you're reading papers and things like that. And so generally, approximation is fine when you're reading papers. So Okay, any questions about the log level model

Speaker 2  13:12  
Steph? Can you give us an example of when there is a Q unit change in x? How does that formula go

Speaker 1  13:21  
absolutely. And so the two is going to come into this delta x right here in the equation. And so where this would come in in our like in our R code, is that we would be multiplying the coefficient by two. So you would just put a two there.

Unknown Speaker  13:43  
I see, thank you.

Speaker 1  13:45  
No problem, right? So if you wanted a 10 unit change, etc, etc, you can put that. You put that all in here. Awesome, great question. Any other questions about this? Log level model? I

Speaker 1  14:07  
Okay, okay, so next up the level log model, right? And so this is reverse. This is when we're logging our independent variable with a level or like normal, not log dependent variable. And so in this case, we're looking at logged profits, and its effect on salary, and salary is in 1000s. And so in this case, we're looking at a percent change in x, right? Because this is the logged variable, and that's going to be associated with a unit change in y. And the way that we're going to find that unit change is by taking the log of, like, the proportion of the percent change we're interested in, over 100 and so for for this one, if we're interested in a 1% change, that's going to be 1.01 right? Because it's just 101 divided by 100 and then you can increase your P. If you want a 10% change, 100% change, then you'll just be putting that in for P here, taking the natural log of that, and then multiplying that by beta one, and that's going to give you a unit change in y, because y is level or not logged. And then the approximation of this is just that a 1% change in x is associated with a beta divided by 100 unit change in y, and so we're just dividing beta by 100 and so what I mentioned earlier about kind of like messing around with this, is that we know that basically, like, the value the log of the proportion net change. Like, how much does that approximate? Like, dividing by 100 right? And so, like, the closer. So like, you can kind of mess around with your value of p to see that, like, the lower p is, the closer it's going to approximate, the higher P is, like, the further away it's going to get. And so the approximation is going to get worse, right? And that's like the same thing that you can do up here. You can see that, like you're dividing 100 by this is like a little bit trickier, but I think intuitively, for me at least. But you can see that, like the approximation is also multiplying by 100 and so this change is in like, how you're looking at your beta as, like, raising E to your coefficient and subtracting one. And so you can look at like, as you change this value of x, this change in x, like, how does the approximation between this value and the and the and beta change. And so you'll see here as well that like as you increase the change in x, then it will be a worse approximation for beta. Okay, so let's run this model right, and then just practice interpretation. So we know that the coefficient on log profits is 196 right. And let's say that we wanted to look at a 1% change in profits. We would say a 1% change in profits is associated with a and then this would be when we're logging 101 divided by 100 and we're multiplying that by our beta. And so I've calculated that here, right? So it's going to be a 1.95 unit change in salary. So we're talking about our log independent variable is a percentage change in that independent variable, and how that is associated with a unit change in our dependent variable. In this case, it's salary. And so a 1.95 unit change is 1000 like is almost $2,000 increase in salary. Okay? And then the approximation we can see is like, quite similar. It's also almost $2,000 increase in salary, but slightly different, with a 1.95 compared to 1.96 Okay. Are there any questions about, what is this level? Log models, a normal y with a log x.

Speaker 1  18:50  
I think I saw from the slides from lecture that you also went through, kind of like a proof of like, how this, how you get to this equation. And so if you're using logs a ton in your research, then I would definitely encourage you to maybe try to develop, like, more of an intuition around what like changes in x like how changes in log variables relates to changes in the variable, but, But for most of us, kind of relying on this formula and the approximations will develop enough of an intuition. Okay, and so then the last thing, log. Log model, when we're logging both the independent and dependent variable, we basically just combine the two formulas that we just used and or it becomes really simple with a 1% change in X being associated with a with the coefficient percent change in y. And so here you can see that like I'm literally just nesting the two equations that we already have, right? And so we're putting in this log proportionate change in x, right? Like 100 plus p, over 100, we're putting that in for delta x, and then that's going to give us this percent change in y. And then similarly, like, the lower the percent, like, you know, a 1% change is going to be a poster approximation. And so, you know, when we're looking at this approximate, we're going to focus on just 1% changes in x1, being associated with the coefficient percent change in y. So if I run model four and take a summary of it, if we wanted to be more precise, it really just changes from point 2228, to point 2219, like, very, very close. And then the way that we would interpret this right is that a 1% change in x, which in this case is profits. 1% change in profits is associated with a 0.22% change in salary. So both are in percent, right? And so we don't need to worry about the units of either in terms of 1000s or millions, because we're take we're talking about like factor changes or percent changes in these and then the approximation is also, is like, literally just the coefficient. Now, which is great. So we saw the coefficient up here is 0.22 as well. Very, very similar. Okay, any questions about log log models.

Speaker 1  21:47  
Okay, so I think one last note about logs or something that I think kind of transitions into into the next topic of their polynomials and and interactions is that you can think of logs as because it's these proportionate changes now in in X that it's basically, you know, the marginal effect of of x on y is now dependent on the value of x, Right? So when we're talking about these percentage changes, the value of x matters, right? And so that's and so we here, we're really just focusing on, like, interpreting these things. But then in the next section, we're going to be looking at quadratics and interactions that are kind of like, easier to, I think, more intuitive and easier to start practicing, like, how to actually think about these marginal effects, or any effects that rely on another independent variable, or the same independent variable, if it's a quadratic um, so that brings us into conditional marginal effects. Um, so I'm going to be going over this with the same data set that we used last semester. The tree is data set. So like a lot of this is review from last semester, and hopefully familiar, and then kind of giving some hints about the problem set this week, because we'll be doing some of the same stuff that you've been doing, either in either in the problem sets this semester or the problem sets last semester, with a couple like, new ways of, like, applying the techniques, if that makes sense. So the lots of different questions that are all using like, the same methods like that you're familiar with, you just might need to get a little bit, like, strategic and I think it's great for, like, solidifying all this information, because you're going to need to think about exactly how to use this to get the answer I'm interested in. Okay, so, so conditional marginal effects is just when the effect is polynomial. So when you're squaring a term or or cubing a term, in this case, we're going to focus on quadratic squaring, or there is an interaction with another independent variable, then the marginal effect becomes conditional. And to find that conditional marginal effect, we just take the first partial derivative with respect to the independent variable we're interested in. In this case, I just called it x1 but it could be any of the x's. And so in kind of polynomial or quadratic, that effect is going to be that marginal conditional. Marginal effect is going to be conditional on the value of x with of the like the same variable, whereas with an interaction, it will be dependent on a different independent variable. So to go through an example with quadratics, this would be just like squaring one of your terms. And so let's think about how the volume or how height effects volume. If we're looking at this kind of quadratic model. And so the way that we would find the conditional marginal effect of height on volume is just taking that partial derivative of volume with respect to height, and we're going to find that it's beta one plus two. That's just like the squared term coming down beta two, hence height. And so this is where that conditionality comes in. Of like, suddenly, this effect of height on volume actually depends on the height of the tree and the value of height. Hopefully, this is familiar from last semester, so I'm just going to be loading the trees data set. I'm going to be estimating my quadratic model. I'm just calling it m, and then I'm basically just making sure that this is considered one term by using the I in the parentheses, height squared. And so we know from up above that the effect is going to be this formula here, beta one plus two, beta two height. And so we're basically going to be calculating that across the range of height. So this should all be review. So just like we did last semester, we're creating a range of height. And I also think you, yeah, you all have been doing it a lot this semester to, like, when we've been plotting predictions, we've been creating ranges of some variable to then predict the other variable across that range. And so the only difference now is that instead of predicting, like, volume. Based on this range, we're predicting the effect of height on volume across this range, but, but it's the same method, right? We're taking a sequence from the minimum value of height to the maximum value of height by an increment of 0.1 I've also seen some of you and I sometimes use length. Dot out equals 100 which just means I want 100 values between these, between the minimum and maximum. But either works. I think I've also seen people get tripped up on if there are NAS, this won't work, so just make sure to include na. RM equals true if there are Ma's or clean your data ahead of time. Okay, so then we're going to be calculating the conditional marginal effect. And so that is just this equation up here. And so the first coefficient, beta one, is just the coefficient on height. And then we're adding two times beta two, and then across our values of height, right? So we're multiplying two by beta two, which is the coefficient on the squared term, and then we're multiplying it by height. And height, here is a vector of values. And so we're basically just going to be getting our output the conditional marginal effect of height is going to also be a vector, right? And so that vector is telling us the conditional marginal effect of height at each value of height in this vector. And then we plot that. And then last semester, I know that we talked about, we talked about calculating, like, the standard errors for this kind of using the the linear combination, or like the variance of a linear combination. And we are not doing that. It doesn't seem like we're doing that yet in this class. And so you can hold on to that for the future. For now, we're just plotting conditional marginal effect quite simply, like, it's just one way of seeing, like, how the marginal effect changes across values of another variable. Okay, so if I run all of this, we're gonna see this plot in my bottom right hand corner. And so this is a plot, obviously without standard errors, but it's just showing us how the the effect of height on volume is going to change across values of height. So then, if you want to know, like, what is the effect of height on or the relationship between height and volume at like, an average height tree, like, let's pretend that the average is 75 we can go up and this is going to tell us the relationship between the two. So just be mindful of the fact that this isn't a prediction. This isn't volume. It is it is just, it is an effect. It is the relationship between high and volume. Okay, so that should be review, yes, sorry, when you say that, it's not a prediction, it's just, it's just showing accurately. So that's you're just saying that we should set our range to be whatever the range of the actual data is. No So, so it's not telling you the so what I mean by it's not giving you predicted values is it's not giving you the predicted value of volume. And so you don't want to use the range of volume in your data set, because what we're actually plotting is the conditional marginal effect, or the relationship between height and volume, which is also an estimate, right? We're basically plotting like the combination of beta in this case, it's beta one and beta three. No, beta one and beta two, yes, like you can see here on line 113 we're looking at this like we're plotting this linear combination of coefficients, right, and both of those coefficients, beta one and beta two, are estimates. And so it's not like we're we're not plotting anything like true or accurate or like observations. We are plotting estimates. But we just want to be like, really in, you know, cognizant of what those estimates are, which is of a relationship or an effect. They're not estimates of like some quantity, like volume, yeah. And so here, like, what if you wanted to set the range? Um, I basically looked at the at the range of my conditional marginal effect, which here was, like, between zero and four. And I guess I wanted to include, I decided to include, kind of like the axes, and so I put it to negative two, but probably not something that you necessarily need to do. You could have, like, changed the ranges of this, but it'll be the ranges of a pre conditional margin, not the range of volume or some other variable in your data

Unknown Speaker  31:48  
set. Great question.

Speaker 1  31:53  
Does anyone else have questions about, like, what we're plotting here, or any questions about kind of this in general. Cool. So now as a great point of comparison, actually, and something that you're going to be doing on your problem set is that this was like one way of like plotting and thinking about marginal effects and visualizing it the other way, especially when, when the when it's like a quadratic where it's based like your the conditional marginal effect or volume is still only based on like, one variable, right? It's still like all to do with height. There's no other variable included. Then it can be much easier to plot predicted volume by height. And so that's what we're going to do now. And so this is very similar. This is like, similar to what you've been doing like, all semester, which is basically creating a data frame across the range of height and then predicting volume using the predict function. And so you'll have two vectors, right height and volume, and you can combine that into a data set. Or I don't even think you need to combine it necessarily for base r plotting, but if you were using gg plot, you need to combine it into a data set, and then we're basically just going to be plotting height along our x axis and then looking at predicted volume. And the reason that we can do this is because, even though it's a quadratic the only like variable that we need to know the value of here is height, because we're obviously just square in height and so and so, we can still kind of look at it on a plot. But my question is, what do you think a plot is going to look like? How is this going to look different than other times we plotted predictions? So think back to like the problem sets when you've plotted predictions in the past, what have the plots looked like?

Speaker 1  34:06  
Straight lines? Yes, perfect, straight lines, right? And so is this going to be a straight line? No? Yeah, perfect, right? And so that's just going to show us that, like the the slope, right or the relationship between height and and volume is no longer a straight line. It's no longer constant over the range of of height. It's going to change. And so if I plot this here, we can see that that is a curved line. Wonderful. Okay? And then here we're going back to kind of the like visualization that we're used to, in terms of, on the y axis we're now seeing volume, and then on the x axis we're seeing height, right? So, like, a little bit simpler for us to see, in terms of, like, what is the predicted volume for a tree with height 75 so that's also like a difference from the last thought that we saw. Okay, any questions about quadratics. I also think, I think something that might be helpful here as well. So I use the predict function, right? Because we want values of volume across the range of height. You can use the predict function, but you can also, like, think about this formula when you're thinking about predicted values of volume. And so, you know, if we were to ask these questions on the problem set about, you know, what is the predicted volume of the of a tree that has height blank, you're going to be focused on this equation, right? But then if you, if we're interested in, like, what is the relationship between height and volume at this value of height, then you're going to be interested in this formula, right, which tells you the partial derivative, or the like, marginal effect, awesome. And you won't be able to tell us the relationship between height and volume unless you also specify the value of height, because it changes at different values of height. Okay, great. So then for the problem set, you'll just be getting creative, basically with these two, with these methods, in terms of thinking about both the like conditional marginal effect and plotting it and finding the effect at different values of your variable interest, and then also thinking about like the predicted dependent variable at different at different values of of your independent variable. Okay, any questions on quadratics before we move on to interactions? Awesome. Okay, so now another model that we're familiar with from last semester, we're looking at an interaction in your labs from last semester. I show you how to plot the marginal effect, like this code that we did here, we've done with height twice, obviously, height and height square, whereas we know from last semester that we can basically do that same exact method, use the same code, but switching out height for girth, if we were looking at the interaction between girth and height of the tree. And so I didn't want to repeat that, because I think we're all familiar with that, but I figured we could kind of do that second method here, the second strategy of kind of visualizing marginal effects, which is looking at like the predicted dependent variable on the y axis across a range of some independent variable. And so in this case, I want to look at the predicted volume across different across the range of heights, right? But then an important note here is that we have to specify the width of the tree or the birth of the tree. And so because we can't know the predicted volume, it is dependent on this value, right? And so this is actually really similar code to what you've been practicing since problem set one of this semester, in terms of, I think you've plotted several graphs that look at, like different percentiles. And so in all of those graphs, right? We've seen parallel lines at different values of family income, at different ages, whatever the different colored lines represent, they've been parallel. And so what do you think is going to be different when we're plotting the same type of graph? But for an interaction model, i It

Unknown Speaker  39:05  
will be curve.

Speaker 1  39:07  
So won't necessarily be curved, right? Because we're not looking it won't be curved. It's more about the difference between the lines, right? So we're going to be plotting different lines, and each line is going to represent a different girth of the tree, right? And so in the past, when we looked at, like, different lines representing different values of family income, right? And then we've looked at, I don't know, some other other independent variable, its effect on voting, let's say and then we say, like, Okay, if the relationship between the independent variable that we're interested in, let's say education, right? The effect of education on voting is independent of family income. In other words, like family income, it does not moderate the effect of education on voting, there's no interaction between the two. And so if the effect of education on voting is not conditional on family income, then the line will be parallel. The lines at different family incomes will be parallel, right? Because the relationship between the two is going to be the same, and that relationship is the slope. So if, in this case, the relationship is conditional, right? So the relationship between the two is going to change depending on the value of G. Are those lines going to be parallel? No. No,

Speaker 1  40:46  
no, okay, I think I see some nodding and stuff like that. So we know that now the lines are going to be different, right? Because each line, the slope of each line, is representing this relationship between height and volume at different values of birth, right? And so you're going to be using the same exact code, which I'll show below. And then we know that we can expect that these lines are no longer going to be parallel. So I'm estimating an interaction model and just calling it MI, or model interaction, and then I'm doing the same thing with the height values as above. So just taking a sequence from minimum to maximum, and then I'm inputting birth values. So I think in the data set it goes from like eight to 23 so I just said 1015, and 20. But you could find this the similar way that you did in the problem sets, if you wanted to look at like quantiles and stuff, or percentiles and things like that, with the functions that we're familiar with now. But here I just put in, and I think actually, for this data set, you're just going to be putting in three values, and then I'm creating a data set that contains every every combination of height and birth, right? So it's going to combine these three values with every value of height. And so whatever the length of height is, it's going to be multiplied by three to get you the length of new data. And then the new data will just be two variables of three times the length of height. Okay, so we have that new data now, then we're going to use the predict function. We're really familiar with all of this at this point, hopefully, and we're going to be predicting volume. And so we're going to use the model, interaction model, and we're going to put in our new data, and that's going to protect predict volume for every combination of height and girth. So now we have predicted volume, and you can see here that it's 723 variables, which should also be 723 in new data as well. So you can see like how that's lining up, which is three times 241, etc, etc, etc. So these are all great sanity checks, especially when you get errors, to look through stuff like this to make sure that everything's happening the way you expect it to. So I'm going to be using GG pop, because I think it's much simpler when it comes to graphing this. But you have examples of base r from your from previous labs and your prior problem set. So feel free to look back at that. If you prefer to use space R, we're going to be using this predicted data frame. I did not on that line. There we go. So now I ran that line so it's in, and that's just that's now we're looking at three variables, as opposed to two variables, because we're adding volume to this data set now, okay, and then we're going to be running this PD plot. We're going to be looking at height on the x axis, volume on the y axis, and then we're going to color the lines based on girth as a factor. And so, you know, there are three values, growth 1015, and 20. And so each line is going to represent a different value, okay? And then we're just going to run this, and we're going to see, like as expected, that these lines are no longer parallel, because now the relationship between tree height and tree volume is dependent or conditional on birth, and so that relationship which we see in the slope of this line is going to change, so the slopes of the lines will Be different. Okay, so let me see. Great, we're done kind of early, like that's all of the material that I wanted to go over today. So we can talk about the problem set. Let me just stop sharing for a second. And so if we wanted, I can go into talking about like binary outcomes, which we would you guys all practice on the problem set. I could talk about like Q Q plots and the Q Q norm and q not line that you use in the problem set. Otherwise, I can just stick around for questions. Or you are welcome to leave early. You're just going to be using all the stuff that we did in mom today. Um, in mom today creatively to answer the different questions on the problem set this week. But I don't think it should be too difficult, like, hopefully this is kind of like a break week, stuff that you guys are familiar with. Just make sure to be Be careful in your interpretations of logs and interactions. Okay, so I'm getting notes that it would be helpful to go over binary outcome variables, so I'm just going to start talking about that. Feel free to stop me if you want to ask a specific question. Otherwise, you're welcome to leave if you if you don't need a review of this. So in the problems of last week, we basically created a data generating process for a binary outcome variable, where the probability of that outcome taking a value of zero or one was determined by a linear combination of independent variables. Right? So we had that equation that had y star equals some combination of x1 and x2 and then we're putting y star into the binomial to determine whether or not our outcome y takes on a value of 01, and then we did simulations of this, and things like that, which I think is More like coding, coding heavy and stuff that you're familiar with and like practice of making functions and for loops and things like that, but in terms of interpreting the binary outcome variable, I think something that you know is important, and one of the questions on the problem set is How the residuals are distributed, right? So you all plotted the residuals, hopefully as a histogram. I feel like that. For me, is the easiest way to visualize it, to visualize the distribution, and you'll see that it doesn't look like the bell curve that we're used to, right? And so it's so that kind of gives us the hint that they're not normally distributed. Would anyone like to give a go at explaining why the residuals are not normally distributed? Or I'll wait to see if anyone would like to give it a go. But if not, I can kind of jump into

Speaker 3  47:39  
it actually, I have a question, because I don't know if I draw the right residual plot, but mine has like two distinct column that the like the points groups towards, so I don't really know if that's normally distributed or not, and I tried drawing like a histogram of the residuals, and that one turns out to be quite close to normal distribution, so I'm just kind of confused. Like, is there something wrong with my interpretation? Or

Speaker 1  48:18  
Yeah, so I can definitely look through your problem set specifically, like, as I'm going through it, and I'll leave notes and everything like that. Or you can stick around at the end and, like, share your screen. But I would say, like, generally, what we're thinking about is that. And I know that sometimes, because of the because we set a seed for this, like, sometimes, like, these things will, like, look normal, like, by chance, but in this, we can kind of see that at least, like, if it did look like a little bit of a curve, it was definitely like flatter than most of the distributions that we've seen that approximate normal. And so I'll kind of just jump into like, how to think about this, and that might also answer your question. And so. So the first is that our y variable can only take on a zero or a one, right, because it binary, whereas our predicted y, because we're putting this into an LLS function, is constrained between zero and one, but will take on different different values, right? And so what we're looking at here is that we're basically the coefficient can be seen as kind of like a change in probability of the Y taking on a zero or a one, and so and so, where the residuals come in here is that the variance in the residuals now depends on our predicted value of y, and that's because, if you think about like y star, is This probability right? If the probability is close to zero or close to one, the variation will be in the residuals will probably be quite small, right? Because it will almost always be predicted close to one or close to zero, whereas, as the probability is 0.5 where you're going to see more like variability in the predictions, then the variation is going to get larger, right? And so that basically is, by like definition or by design, creating heteroscedasticity, right? Or like this, this, the variance in your residuals is going to change across the values of y, and so that's kind of like the, you know, the different parts of the answer that we were looking for at why we wouldn't expect residuals to be normally distributed here, because they're going to be and, like you mentioned, like they're going to be clustered around, like zero or one, kind of depending on on the value of p, right? Because the if, the if the real value is either zero or one, and then you're predicting, you know, this range, it's going to kind of depend on the probability of, like, the size of that error. Does that make sense?

Speaker 3  51:22  
Um, I think, Could you, could you show us like what the residual plot that you're looking for would look like? Because I am really not sure if what I drew was was correct. Yeah,

Speaker 1  51:35  
yeah. Let me pull it up right now. Um,

Unknown Speaker  51:46  
um solutions, okay, so let me share our studio. I No,

Speaker 1  52:03  
okay, so you can see the solutions here. This is our data generating process, right? So we're putting in the probability Y star, putting it into the Bernoulli distribution to get our y and then we are running this here, amazing. And then we're creating a data set. I included all of the things in the data set, but you really just need your Y, your x1 and your x2

Speaker 1  52:38  
and then you are running a line model on this. And so you're like, forcing it into LS, right? And so now I'm really using base R to plot a histogram of the residuals, right? We can kind of see, oh, wait, I did not set my seed here. I don't think did I set the

Unknown Speaker  53:00  
seed? Yeah, you did, okay, perfect,

Speaker 1  53:02  
right? And so we can see here that this is, like, I know that it, it is, like, a little bit confusing, that it kind of looks like a bell, fake curve, like it, you know, kind of resembles a bell. But what we want to focus on here is that, like, this is pretty flat, right, with like, some at the extremes, right and like, most of the errors this makes sense are between negative point five and point five because, like, sorry, I'm getting messages at the same time trying to pay attention to everything right? It makes sense that the residuals are primarily between negative point five and point five, because we're constrained between zero and one. And so this, I know that it's like, maybe we should have gone through more seeds to see if we couldn't find a seed that was like more clearly. But this is what it will generally look like, which is, like, pretty flat between negative point five and point five, and then, like, maybe some extreme values. Okay,

Speaker 3  54:08  
I think, I think I got Why mine was weird, and a few of the people also messaged, perhaps is because residual plot could be understood in a lot of different ways. And yeah, what it is, the y axis is the residuals, and then the X axis is the true y value. That means it only has zero and one, and so it like two lines like this. So I Yeah,

Speaker 1  54:32  
yeah, yeah, yeah. And so that is tricky, and I'll be and I'll be grading this for everyone. And so I'm generally fairly, like, generous with grading for things like this, because I guess we didn't specify his histogram. I would say, like, the hint in this was, like, thinking about the distribution, it's going to be easiest to see a distribution with a histogram, but yeah, and then and then. But you can also see why, if you are plotting, remind me, you were plotting the the true value of y to the residual, or the predicted value of y to the residual true value of Y, yeah. So then it makes sense, right? That you are seeing these two lines because the true value of Y can only take a zero or one. Okay. Yeah, that's that's although putting all of this together is like great learning. So I think hopefully a worthwhile exercise, none the less. Okay, any questions on on this before we move on to the next question, which is kind of looking at the Q, Q norm, yeah, so I

Speaker 2  55:39  
have a question for like, the histogram. I know you said, like, the value supposed to be between 01 but like, Where are their extreme value?

Speaker 1  55:51  
Or, like, oh, it's because, um, so the value of the predicted Y is constrained between zero and one, but the residuals are going to be between negative one and positive one, right? So like, if the like at the extremes. So if the if the model predicts like a zero, but it was actually one, that would get you an error of one, whereas if the model predicted one, but it was actually zero, that would get you negative one. But because we're using OLS, it's it allows like predicted values to take on, like any value between zero and one. And so that is what you know, and that's why kind of we're seeing like the biggest range of residuals in this point five region. Thank you, yeah, yeah. And then I think you maybe went over this with the with Chris when he did the chile data set. But basically, you know, a way to think about it is that our coefficient is now telling us, like, the change in probability. And so if you had a, if you had like, it tells you like, okay, between a zero and one, like, between 0% and 100% like this variable taking on, you know, one unit increase, or a lot of the a lot of the variables will be binary in that case, like, I think in the voting, it's like party, party and stuff like that. So it's like, if you are the Conservative Party relative to the Liberal Party, your chance of voting for the status quo increases by this percentage, or by this proportion, percentage points, yeah. So it'd be, like, 0.22 Yeah. So does that? So does that make sense? Kind of this difference between, like, the actual value is going to be zero or one, but because we're using OLS, we're getting these, like, weird between zero and one values. Okay, so now I'm going to go down so this is all like the simulating functions that that we're familiar with, and then we run the simulations. And what we're doing is we're running the simulation for different sample sizes. So n equals 10, 101,010 1000. And then we're using Q, Q plots to compare the distribution of your beta because each of these simulations is taking out beta two, no beta one, this coefficient right here. And so we're now the simulation is going to be spitting out that distribution of beta one. Sorry, we'll have to keep track of beta one. And then we're going to be using cookie plot to basically compare the distribution of beta one to some theoretical distribution. And in this case, because it's peaking norm, it means we're comparing it to the normal distribution. And so this takes a second to run each of these, because it's so much control, just like, start that running, and then hopefully I can. But basically, just to go over what like Q Q plots do is that they're going to compare the distribution of a data set. So this is our data set of betas to the normal distribution, or whatever theoretical distribution you want to compare to. And so the quantiles, it's quantile plot, which is where the Q Q comes from. So it's going to plot like the quantiles of the theoretical distribution along the x axis, and then the quantiles of your of the data set in on the y axis, um. And the q q line allows us to plot the line that like if it perfectly matched the theoretical distribution the your QQ norm plot would line up against it. And so you're basically just comparing your dotted line to this straight line, and the closer it is to the line, the more your data approximates the normal in this case, because we're using Q norm, obviously, if you were comparing it to some other distribution, it's just how close it is to whatever distribution. Okay, so now that we've run this, we can run Q norm, which you can see comes up in my bottom right hand corner. Right is this line, and then I'm also running Q line to get that theoretical line, right. And so what we can see is that, like the tails are diverging from the normal distribution, right. But then the really important thing that we want you all to see or notice here is that as we run this, the line gets closer right, which means that the beta distribution is more closely approximating the normal. And then we ask you to interpret this, and this is like the same stuff that we learned last semester and that we've continued working on this semester, which is kind of these, just like asymptotic properties of OLS. And so we know that, like o, l, s, the s, the estimate for beta one is a linear combination of random variables, like based on the the fact that it's predict it's the relationship between x and y, and y is dependent on this linear combination of x1 and x2 and so we know that, like by the central limit theorem, that the distribution of this sum of independent random variables is going to more closely approximate normal as your sample size grows. So, like, even though the individual errors are not normally distributed, which we saw earlier, the mean of those errors will follow a normal distribution. And so, like, as the sample size increases, the sampling distribution will approximate normal I mean, it's all just ways saying the same. And you didn't have to say exactly this in your problem set. I basically just said it a bunch of different ways, so that you know you you know, like, as long as you kind of said this idea of the central limit theorem, and as simple size increases, the distribution of beta is going to approximate normal that's kind of the general idea that we want you to take away from that problem set. Okay, so any questions on

Unknown Speaker  1:02:41  
problem set five

Unknown Speaker  1:02:43  
on what we just turned over.

Speaker 1  1:02:51  
Okay, any questions on anything about lab? Okay, great. Well, then you guys will be doing problems at six this week. Should be pretty easy. I hope you know, should be familiar, and all the stuff we went over today in class, and then we'll give you more information on kind of think the mid term is coming up, and so we'll probably be doing review for that next week. Okay, great. We'll have a good weekend. Everybody.

Unknown Speaker  1:03:27  
I know you were keen disruptive,

Speaker 4  1:03:34  
just Sir, you don't be disgu. Ignored, come to me. Come to me, baby,

Speaker 5  1:03:47  
come come Yes. One to Oh, close, close i. S.

Speaker 5  1:04:30  
Oh, my. No, I know it's difficult. You smelly, blessed your breast is so stinky so stinky.

Transcribed by https://otter.ai
