Unknown Speaker  0:00  
Think about we're

Speaker 1  0:06  
talking about what happens when we violate a different assumption. Heteroscedasticity is about violating the unconditionality of the variance of theta, while this fourth assumption, right is about the correlation of the error term previously with heteroscedasticity. We're talking about an association between the variance of the error term or the access here we're talking about an association between the error term itself and the independent variables. So to the extent right that the expected value of the error term is unconditionally zero, that it doesn't co vary with the independent variable, then we say the independent variables are exogenous to the extent that there is a correlation between the error term and one or more independent variables, we say that there's a problem of a problem of endogeny. So an independent variable in your regression model that's correlated with the error term is an endogenous independent variable. And why we say endogenous, right? We say endogenous because endogenous is a general using that term generally means cause within the context of the model. So endogenous means cause within the context of the model. And if it's, if it's correlated near a term, it's it has a cause that's within the context of the model. You can't treat it as if it's just completely external. So in what different ways can we end up with this problem? The main ones, if not, might even be comprehensive, I guess, right, we had, we can have omitted variables. This is sort of the most common one that you think about, when you think about endogeneity, you have a regression model and you're worried that there's some variable or variables that you didn't measure, and then you didn't include in your regression model as predictors that are correlated with the x. So there's no there's one or more omitted variables, in the sense that there are variables that are correlated with x that are in the error term. The fact that they're in the error term means they also cause y, right? Because what is the error term? The error term is just the error term is a portion of y that is independent of the independent variables, right? It's independent of the x. So to say that there's a variable in the error term correlated with the X is to say that there's a variable that both is associated with the independent variable and associated with the dependent variable. And that's what we've often talked about as the condition for, you know, a problem of Omitted Variable bias. Right? We have a simple model of X on Y, but we're worried about a Z, right, that has that kind of relationship. This is the classic omitted variable. We don't measure Z, we're worried that this is a spurious relationship, and that's just another way of saying that when we don't measure Z, right, it goes into the error term y, and we know it's correlated with x, and so we have a correlation independent variable, and the error term, the second way that this can happen, and we'll talk about this at the very end. You'll see why is if we have measurement error in the variables, that can also cause this problem of endogeneity, and the idea being that sum of X is in the error term, essentially, and then finally, reverse causality is also sort of a classic way that this happens, where we want to say that X causes Y, but it might turn out that y also causes X, and if y also causes X, Then the part of y that's not caused by x is in the error term, and that part also causes X. So now we have a relationship between the error term. So all three of these are possible. This is sort of the one you think about most often. This one as well reverse causality is very common to think about theoretically. This one we tried, I think most we're just, most of the time, trying to pretend doesn't exist, because it's present everywhere all the time, almost everything we do as social scientists, and there's very little we can do about it most of the time. And so we just pretend. I'll give you a little hat took to Dan signaller teaching measurement models next semester. There are ways to try to go about doing this, especially through research design and so. But I'm bias, because I really like so. I think the type it, it's the first time he's teaching it, and so it doesn't have an official number yet, so I think it's like a special topics course in the fall. But, yeah, yeah, the latter one is, is, like a temporary code, I think, for this, until he gets a formal number. But it will be measure. It'll be something called something like models or measurement so, like, if you're wondering about that kind of thing, right? Like, one way to start thinking about dealing with measurement errors in the context of like, I mean, the way I heard about before is factor confirm word factor analysis or item response theory, or, you know, that kind of scaling type literature. And so that's the kind of topic, you know, that and other related topics I cool. All right, so let's sort of get into it. So let's think about a population regression equation, by which I mean it's like the true model right in the population. And what we're going to do is we're going to decompose the X so the X variables into two different components. We're going to say that our typical sort of x, without any super script, is our X variables that we're including in our regression. You guys measure them, and they're going to be in our estimation procedure. We've got a subset of the overall independent variables that we'll superscript with an O that we'll call omitted because we didn't, either didn't measure them and can't include them, or we didn't. So they're omitted in the sense that they don't appear in our estimation procedure. But the key is that this is the true population model, so they should be in there, but we didn't do it. They should be in there because they actually have an effect. And that effect is gamma. We'll call it gamma. Contrast it with theta. They have an effect. Gamma is non zero in the population. But we've excluded those variables from the model, and so we're implicitly and erroneously fixing gamma to zero. We're treating we're treating this as if gamma was zero, when, in reality, it's non zero. And so these are omitted. What does that mean? Well, that you know, just because we have gamma zero, it doesn't mean it actually goes away. And it doesn't actually go away. What happens is, in our estimation, it just ends up in Europe. It's truly there in the population equation, but we're just treating it as if it's not. So what happens to it is that it goes into an error term. And so now the error term is just this whole thing at the end, we'll call that use as super script star to distinguish it from the population error term. So the population error term is the true error term. We estimate an incorrect model where we fix we pretend like this doesn't exist. That shoves it into a new error term for our estimated model, which we'll call u star. So the model we estimate is y, x, beta plus u star, and so now we've got our omitted variables in that area.

Speaker 2  8:35  
Yeah. So gamma is actually zero, then x, O is just part of U, right

Speaker 1  8:41  
if gamma, if gamma is actually zero, then, then it's not, then this model is incorrect. So this model, if gamma is actually zero, then there's no problem, because this doesn't have any effect on y. And so when you estimate the model without x zero, you just have u star equal to u, because if this is zero, this drops out and it's gone, and if it's gone, then you can just say u instead of u star. Makes sense. The other way to say it would be, if this is truly zero, then this is zero, and u star is equal to u. So and that's exactly what we're saying over here, right? If Z affects x, but not y, then there's no problem. It's only when it when it's correlated. You want to follow up on that. Yeah, I'm thinking,

Speaker 2  9:37  
because gamma is the so gamma, is it the correlation or just the effect of

Speaker 1  9:45  
Well, let's not cause a language on it. Let's just say it's, it's, it's the partial. It's the partial relationship between X, O and y, after accounting for X without the superscript. So anytime that's zero, right? Like you can, you can write this if you want, but because this is zero, this drops out. And once this drops out, now u star is just equal to u, and if this is correlated with with this, it doesn't matter if it's not even in here, so and then. So that's, that's sort of one of the big points, right? If gamma is zero, then it's not actually in this model. So then it's not in the error term. So then there's no problem. If gamma is non zero, not zero, then it is in the error term. And then the question becomes, if it's in the error term, is it also correlated with that. So if X superscript O is correlated with x, then that, by definition here, right? That means x is correlated with Q star. That's exactly the assumption that we're worried about. So we're going to estimate an equation now, right? If you make these, if x O is both, you know, has a non zero gamma and is correlated with x. That means that the error term the model we estimate is correlated with our are included, and that's the definition of endogeneity that violates our key assumption. And that means that our estimates of beta right are no longer unbiased, and then they're no longer consistent. So this is just another way of saying what's going on here and showing exactly why this sort of classic, you know, triangular way of talking about admitted variable bias is true because the thing that is omitted goes into the error term, and because it's correlated with x, it induces a correlation between the error term. And that's why the problem says, in order to prove unbiased, we had to make this assumption. Once we can no longer make that assumption. We can no longer prove it's unbiased. And because and consistent,

Unknown Speaker  12:07  
okay questions that's

Unknown Speaker  12:17  
confusing.

Speaker 1  12:29  
So, so this is an issue, right? Obviously, we don't want an we don't want a bias and inconsistent there. So we got to think about what the solutions might be available. So we'll talk about two The first are called proxy variables. And the idea here is that, well, the idea in general is that we're trying to break the correlation between the omitted variable, or variables and our included X variable. Again, the problem that we're dealing with is that the error term is correlated with the X variables in our model. If we can somehow break that correlation, then we're good. In order to break that correlation, we need to break the correlation between the omitted variable and the included term. So how can we break that correlation? Well, one strategy is, well, the best strategy is to include the omitted variables in the model that, by definition, breaks that correlation, because now it's no longer in the error term. Now it's in the model, but presumably that's not available to us, although it is worth saying, right? It's like a lot of times in the review process, right? Someone will say, I think you omitted an important variable on endogeneity, so like, you should include it as a predictor, as a robustness check or something. And if you have those variables in your model, a in your data, then you can put them in the model and do exactly that's very common. So it's not like this is never going to happen, right? It happens. But you know, usually in the process by which it happens is that you thought this was properly excluded, and someone tells you that they don't believe you, and then you but let's so that's not a very interesting case to consider. That happens practically, that's really what we're interested in. The case where we can't do that right? Someone says, you know, this variable matters, and you need to have in your model. And you say, I didn't measure that thing, and I can't obtain a measure. So what am I supposed to do? And so a second best solution is to use a proxy variable. And we'll, we'll label that with X, super script, p. And so what is a proxy variable? A proxy variable is something that's correlated with the omitted variable. So what we want to include the thing itself, but we can do it for some reason. The next best thing is to use something that we have measured that's correlated with that that's the best thing. That's the best best we could do. And so the question is, well, what are the conditions that need to be met for a good graph? So obviously, it has to be correlated with the thing that you're interested in, so that uncorrelated the omitted variable or variable, then it's not proxy variable. It has to be correlated with what's omitted. But you need some additional condition. So the first one is that the expected value of the population error term given the proxy variable is zero. So this is just that same basic gene, the assumption, but for the proxy variable, another way to say that is that the proxy variable is properly excluded from the true population model. So if we go back to our first slide here right, the proxy variable is not in the model. So it is properly excluded. It has a coefficient vector that's set to zero, it does not belong in there. So that's the first condition. So it's something that you can properly exclude from the true model. The second one is a little more a little more confusing when written out formally like this. But the basic idea is that once you regress the omitted variable on the proxy variable or variable, the residuals are now uncorrelated with the included this is just another way of saying that you're breaking the correlation between the error term. You're saying that once I've extracted the variance in the omitted variables that are associated with the proxies. Everything that's left over is independent of the included exactly it's now these variables are now exogenous, because I've gotten rid of all the variance in O that's correlated with x. So basically, once I over do what we're saying, right? Is that? Right? If z is the omitted variable, x is the included variable, we're trying to break this correlation, and we can do that potentially by including a proxy, right? That

Unknown Speaker  17:22  
is like this

Speaker 1  17:25  
breaks that correlation by being un there's no more relationship between z and x once you've controlled for P for that FRC that was probably using what I was just saying here. Does that? Does that make sense? Yeah, so,

Speaker 1  17:51  
independent variable, actually. So again, sort of the key problem again, is that there's this variable, or variable x, super script out that we didn't measure or we didn't include, and those variables are in the error term now, but they're also correlated to the things we're interested in, and what we need to do is break that correlation, and that correlation will be broken to the extent that if you regress the omitted variable on the proxies, everything that's left over is independent of the access.

Speaker 2  18:23  
So in the example of a wool bridge where the omitted variable is intellectual ability,

Speaker 1  18:32  
I'm going to do that example in a second. Yeah, okay,

Speaker 2  18:37  
but I just thought here, so it means that, okay, maybe

Speaker 1  18:40  
Yeah, yeah, maybe. So just to summarize, right? I know this is this especially kind of confusing. So in words, right, a good proxy must be absent from the true population model should be properly excluded from the regression in general. But also, and it also must be, it must be such that the omitted variable that you're worried about is uncorrelated with the predictors in your model, after you residualize Based on the process. Now, you can never do that in practice, like the whole point is that you don't observe this. You can't run that model. It's a theoretical claim. Well, I mean, I guess if you had a different data set, you might be able to make something associated with it, but in your data set, the whole point is that you don't have this variable, so you're not gonna be able to run that, but you're gonna have to make a theoretical

Speaker 2  19:36  
Yeah, so I'm still a bit confused about the first equation, first slide, yeah, the previous one, like the one now, I mean on the previous slide all the way to beginning this one. So mathematically, this doesn't imply that there is correlation right between you made the predictor and just the normal x, just something that we say, like in that equation. Okay, exactly.

Speaker 1  20:05  
Yeah, it this is a this alone does not tell you that if you omit this forces it into the error term. But there's lots of things in the area and you only care about the error term of y being correlated with this. And so this has, again, like the easiest way to think about this little triangle. The omitted thing has to be correlated with both x and y for it to matter, it's only correlated with y. Well, everything in the error term is correlated with y, by definition, because it's everything in y that's not associated with that. So that's that's not that alone is not enough. It's also not enough, but that any given variable is correlated with x, because tons of things are correlated, it has to be both correlated with x and properly included in the model. And so a good proxy needs to be the opposite. It needs to be properly excluded

Unknown Speaker  21:05  
on the second condition of like,

Speaker 1  21:09  
what a proxy use here, like was, can you explain, like, partially out concept? Yeah, so, so you got this omitted variable that you're worried about. It's in the error term, and you've proposed a proxy variable. You want to be able to say that if I regress, if I was able to regress the omitted variable on the proxy and take the residuals from that regression, that those residuals would be uncorrelated with the independent variable. And the reason is because what you're trying to do is get rid of the correlation between the omitted variable and the included and so what you want is the residuals after taking out the variance associated with proxy to be independent. But I'm going to go through a concrete example, and we'll see if that clears up some of the confusion, I think, in the abstract, this is the example from Wooldridge, which is a good one. We're looking at the wages, some some notion of wages, at the deep time variable as a function of educational attainment, how much experience you have in the industry, and some kind of concept related to like intrinsic ability. So let's say that this is the true population model. But let's also say that while you measure education and experience, you don't measure ability, and you're worried about that, because ability might determine right experience in education. And if that's true and you don't include ability in the model, you're going to be worried about estimating the effect of education and experience. So if you don't observe ability, we might be worried about bias in the other two co efficient estimate. So one thing we might think, let's say, in our data set, we don't have a measure of ability in the domain that we're interested in, but let's say generic measure of ability, like an intelligence test or SAT scores or something, we could use the scores right on that test as a proxy for ability. And what we're going to think about is that there's an implicit model that we're sort of using. So we're thinking that the unobserved ability is a function of this underlying general

Unknown Speaker  23:40  
measure of this intelligence,

Speaker 1  23:45  
right? So if we, if we were able to, we would regress ability on intelligence, and we would get some coefficient, some relationship. So this is the idea of a proxy, right? This intelligence test is going to proxy for domain specific ability. So the way to think about this, then is really what we're doing right is taking this entire model and plugging it in for ability. That's implicitly what we're doing. We can't do that for real because we don't measure this, but what we're doing in theory is taking the model. Let's just do that and see what happens. We plug in that model for ability in place of ability, right there. Now we can multiply the beta three coefficient through, sorry, and rearrange so beta three times delta zero. Well, this is a constant, so let's just group it with the constant in the population equation, beta zero plus beta three times delta zero, where that's the constant from this model. These two things don't change. And then at the end, right, we're getting beta three times delta one times intelligence. So we can put that over here, and then we get beta three times the error term from this model. And since it's an error term, let's just group it with the other error term over here. Well, now let's just rename some of this stuff. So let's rename this whole thing, Alpha zero. Let's rename the product of these two coefficients, alpha three, and let's rename the error term from u to E. Well, what are we left with? Something that's different from the population model. It's different because it has a different intercept. It has a different coefficient for this third variable and it has a different error. But what's not different about it is that that beta one and beta two. So we estimate this model, which we can because, look, there's nothing here that that's unobserved. Everything is observed, educating is observed, experience is observed, and intelligence is observed. So now we can estimate this model and get consistent estimates of beta one and beta two by going through this logic, what we've shown is that using this proxy allows us to get estimates of beta one and beta two. What we can't get are estimates of beta zero beta three, because they're confounded. So we're going to get something will get estimated here, but it's not beta zero. Something will get estimated here, but it's not beta three. But what we can get is beta one. Is the error the same? Like, is there any specific

Speaker 3  26:34  
difference between them, or is it just one would be larger if it's the error for the intercept beta one. And

Unknown Speaker  26:41  
so the error, when you say error, would you be better into

Speaker 3  26:46  
one specific term like that do anything other than service, kind of a conceptual

Unknown Speaker  26:53  
Okay, so these will be less efficient, but

Speaker 3  27:00  
conceptual difference than an app or like we're combining them conceptually, but it doesn't actually change the model. It just makes residuals

Unknown Speaker  27:08  
larger. Yeah. Okay.

Speaker 4  27:12  
So the reason we're saying that education experience should be not really unrelated to the residuals by the intellectual score versus the ability is because, when that is correlated, the E actually now is correlated with the education experience, so that there will be

Speaker 1  27:39  
is uncorrelated. Okay, great. So, so think about so by assumption, right? Education and experience are uncorrelated. They're uncorrelated with you because we're assuming they're exogenous. This is, this is the true population model. You is uncorrelated. So, so you is uncorrelated by assumption. We're also going to make one more assumption right here, which is that after regressing ability on intelligence, the residuals of that are uncorrelated with the other predictors in the model. If that's true, then both you and me are uncorrelated, then this whole error term E is un correlated, is it does.

Speaker 3  28:24  
What you just said, is that word claiming that ability has no effect on education and experience, except as measured by the intelligence test. So once we control for that using the intelligence test, we solve the problem what the editor Incorporated,

Speaker 1  28:41  
that is the assumption you need to make, yes, now that I think that's good assumption, but that is the assumption needs to be made for this to work, for this to be

Unknown Speaker  29:00  
okay, so I'm happy to stick here.

Speaker 4  29:06  
So do we assume, in this case that, because we assume that the correlation between education adherence must be zero, so that

Unknown Speaker  29:25  
we know bias

Speaker 1  29:30  
up here, right now, we don't make that assumption, right? We only have to make that does not be made, right? The problem is that we don't observe and there is a correlation between ability. Now it's a problem we've excluded on the model. So if ability is correlated with these two it needs to be in the model. If we don't measure it, then it goes into the error term. Now there's a correlation between the error term and these other variables, and so we got to figure out a way to break that. If this, if the assumption that the error term in this model is independent of education and experience is true, then we've broken the correlation by including intelligence right because now that whatever is left over,

Speaker 4  30:24  
remember, there is a equation saying that when actually ability is actually experiment. So that ability equation is actually longer, like with sigma two and three by popping and then eventually the estimators of the equation is,

Unknown Speaker  30:47  
I Think maybe you're thinking of the instrumental variable exception and

Speaker 1  31:09  
Okay, feel free to jump in. So if we have a proxy that meets these assumptions, right, we get consistent estimates of the parameters for these consistent estimates for beta one, beta two, not for beta zero and beta three. And again, that's because when we do this rearranging, you can see that we've got a confounded intercept composed of a bunch of different things, and we can't separate them out. And we've got a confounded beta three, because we've got to confounded third coefficient here, because it's beta three times delta one, and we can't estimate them separately here, tied together. So we don't get consistent estimates of these things. They're just different. But we do get consistent estimates theta two. So, yeah, you said that. The last thing to think about, right? It's like, well, in most cases, right, you're going to have a hard time saying, like, I have a perfect proxy variable right here. You're worried about whether, once you partial doubt the variance and ability associated with intelligence, is it really true that B is uncorrelated with education experience? And you might say that's almost surely not the case, right? It's like there's no way it's a zero correlation. And so then you just ditch this entire enterprise. And I think the answer is no, right? In reality, all we can ever do is do as well as we can, right, and hope for the best. And so if you only have an imperfect proxy, and you're trying you want to get some information out of your data, right? Well, you know that's might be the best you can possibly do, and you have to accept that there's going to be some amount of inconsistency in your estimator, but it's probably way, way better than what you would get right, if you just estimated the model without the intelligence state, you estimate the model with just education and experience, you know that you got a huge problem. If you include this proxy variable, even if it's imperfect, you substantially reduce the amount of bias in your estimator. And that's a good thing, and you're doing better than you otherwise would. We're never going to get perfect, perfect outcomes in the real world, and so a good, but imperfect proxy is way, way better than than a model that just ignores the problem altogether. So

Speaker 1  33:45  
one thing you might think, right, maybe one other thing, what we're saying. You one way to think about it is that going on out there,

Unknown Speaker  33:55  
kind of a squirrel right

Speaker 1  33:58  
here, is that you know, in the vast majority of cases in social sciences, you're probably always using proxies in a sense, like, all your variables are just proxy variables. Sense in which that's true, right? Because you're measuring these kind of fuzzy, abstract concepts, like, what would it even mean have a measure of ability? Like, that's a concept that's even hard to define Never mind concept operation, so you're almost always dealing with property variables. That's true, right? Like, maybe that sort of makes you appreciate this last little bit more, where everything is always imperfect.

Speaker 1  34:40  
Okay, so let's take a step and then see if there's questions you I know, Matthew, you had a question at the very beginning. Did this help resolve it? Or yourself? Yes,

Speaker 2  34:49  
just if I understand it correctly, I would say like the second condition of this proxy variable requirements is way hard to fill in the first one, right? Because, like with this example, like you could be really hard to claim that intelligence test that it doesn't have any relationship with education or experience apart from intellectual

Speaker 1  35:19  
business. That's not that is. I think that might be a slight misunderstanding, because you have intelligence in the model, so you're dealing with any residual, you're dealing with any correlation between intelligence and experience and education by having it as predict a model. So that's the issue. Is not that, but you measure the intelligence in there as a control. There's no problem that there's a correlation between intelligence these two. The potential problem is that ability is still correlated, even after this is saying that I've residualized ability based on intelligence, the correlation between these two goes away. And that's what this, this assumption is saying. But it's okay these things because I measured it to control fine agent, also because by now,

Unknown Speaker  36:14  
introducing intelligence, we've also

Speaker 1  36:22  
added I don't think so. I'm actually now starting the question, but I don't think this actually. I think that. I don't think that's actually, I think it could be smaller because, like, let's say no, no, it has to be bigger. What I was thinking was that, well, maybe intelligence has this big effect on y and reduces the error. But if that was true, it would be in the population. It has to be bigger, multi collarity.

Speaker 1  37:00  
I think possible, right? If the proxy is highly correlated together two variables, it might be a higher

Speaker 1  37:17  
Well, it's not, it's not the sign. You have to take the variance operator that last thing, so it's not like a sign issue, because this isn't the variance of the error term. This is just the error term. So when you take the variance of your combination two variables, I

Speaker 1  37:54  
Okay, so that's one possibility, right? Maybe you have a measured variable that meet those conditions, or proxy for the excluded variable, a very different solution that's motivated by the same goal of breaking the correlation between the error term and x. So instrument variables analysis, which I'm sure you come across at least at some point. And so let's, let's, we're gonna start with a simple example to try to develop the logic, and then we'll make it more complicated. So we're gonna start with a bi variate regression. And so let's say this is the model you're estimating, right, and so you're interested in beta one, and you've got one predictor x1 but let's say that we know right, we're we feel very confident that there's no Omitted Variable bias problem. So I'm just going to start with the model we're estimating is one with u star, because we are confident that there's an Omitted Variable bias issue, such that x1 is correlated with the error term in the model we estimate. So we believe that this is true, and so we're worried. And because this is true, beta one is a bias. OS is going to give a bias estimate. So we're starting with a minute variable bias, and we're wondering we can do and let's say we don't really. We either don't know what a good proxy would be, we don't have a good proxy. And so we need a different solution. A different kind of solution is to find an instrumental variable, and we'll call instrumental variable z, an instrumental variable for x1 and for it to be an instrumental variable, it has to meet these conditions. The first condition is that this instrumental variable, this proposed instrumental variable, Z, has to be correlated with x1 the correlative variance cannot be zero. It has to be related to x1 that makes sense. That should be intuitive, right? If it's not related to x1 Why would be able to serve as an instrumental variable for x1 has to be related to the thing that we're worried about. That we're worried is getting bias estimate. The second one is that the correlation, or covariance between that instrumental variable and this error term is equal to zero. And what that means conceptually is that that instrumental variable is properly excluded from this model. It doesn't belong in this model. It really is excluded the model, as opposed to zero in this model. And that's just another way of saying that it's not correlated with the error term. It's not explaining any additional variance of y after accounting for X, once you accounted for x1 there's no correlation between z1 and y, which is just another way of saying it's not correlated here. And that's another way of saying that it's that it would be exogenous. I Right? So put that in sort of like a catch phrase. Your instrumental variable should be associated with the dependent variable through and only through the variable for which it so z1, should be associated with y through and only through x should have no additional effect on y after control. So it needs to be related to x and it needs to be unrelated to y after control.

Speaker 1  41:38  
So this is called the exclusion restriction which you go to, like a workshop talk, that phrase comes up probably half the time. And so this is what people mean by the exclusion. We are assuming that we can exclude the instrumental variable from the true model. In practice, this has to be defended primarily theoretically in most in the vasodian cases, well, not actually in a very large number of cases, it can only be dependent theoretically. There are some cases we'll talk about where you might be able to mount something of an empirical defense, but it's always imperfect. So the stronger your theoretical argument for the exclusion restriction, the more people are going to believe you, even if you have some empirical evidence, I'll talk about empirically, but it's really a lot of weight is going to be put on your theory. And so why does this work? Right? Why do these two assumptions make sense? Well, what we're going to do in instrumental variables analysis is we're going to generate predicted values of the endogenous regressor from the instrumental variable, and then we're just going to use those predicted values to predict y. We're going to substitute the predicted values of x1 for x1 in this model. And why does that work? Well, it works because we've assumed that z1 is properly excluded, that it's exogenous, so any variance that is generated from z1 has to be also exogenous, and that's what the predicted value of x just is right. It is variant in x1 that's only associated with z1 and so if z1 is exogenous, then the predicted values of x1 from z1 also our problem. So z1 is truly exogenous, it's excluded from this model. And if it truly predicts x1 then the predicted values of x1 based on z1 are going to be exogenous, and we can just use them in place of x1 in this model, and that will give us a consistent estimate of data. Another way to put that would be that if those conditions are met right, the expected value of x1 given z1 is both a good guess for what x1 truly is, and it's exogenous in this model, so it can be used as a substitute for x1

Unknown Speaker  44:12  
question. So first I

Speaker 3  44:23  
it's about our estimate for beta one. It's about our estimate for beta one. So if Z explain 60% of the variation in x1 and x1 is explaining 30% of the variation, the beta one estimate we get by using that as an instrumental variable,

Speaker 1  44:52  
not system, no, not systematically, because it it's consistent. So it'll it'll be a consistent estimator. Beta one, it'll be it's not systematically lower, not systematically attenuated, it's systematically more variable, so it's higher variance estimator, which is why, no, that's not quite right. So the issue with using only, so when you think about right, like what, like you said, right? If z, if z1 explains 60% of the variation in x1 then when you generate predicted values, there's still 40% of x1 that's unexplained. And so what you're using, you're substituting predictive values of x1 which is a noisy estimator of this. And because it's noisy, right, it's going to lead to nois, yeah, maybe that, maybe you're right about his wife, consistent. That

Unknown Speaker  46:02  
makes the makes sense, more questions.

Speaker 1  46:20  
All right, so let's derive the instrumental variables. Estimate ends up being surprisingly straight forward, really surprising to me. So we're starting with this model. We have an instrumental variable that we assume, we're going to assume meet those conditions that we just talked about. So let's start by taking the covariance between the dependent variable and our instrumental variable. So we do that on the left hand side. We also do it on the right hand side, the covariance with Z, and we've got the covariance of the model for y. Let's now expand this out. Well, the covariance between a constant and a variable is zero. So that first term is zero, the covariance between beta, one, x1 and z is you can pull the constant out in front, and then it's the covariance of x1 and z1 and then the last term is the covariance of U, star and z1, there for a second. But now what we're going to do is make that assumption. That's p, right? But this is zero. That's our second our first assumption about about the instrumental variable that is properly excluded from that model, which makes this zero. So if we assume that that's zero, this drops out. This is already dropped out, and what we're left with is covariance of y and z1 is equal to beta one. That's covariance of x and z1 well, let's just divide by that covariance on the right hand side. Pull it over here, and now we've got an expression for beta one which is equal to something very simple. It's the covariance of the dependent variable and our instrument divided by the covariance of the independent variable. And this should look very familiar, right? If it's isomorphic, it has the same structure as the bi variate estimator for beta one, the bi variate estimator for beta one in OLS is covariance of X, of y and x over the covariance of X and X, or the variance. And so it's the same structure, but we have an instrumental variable that is substituting in for x. So that's that, right. But for the binary case, that's what instrumental variables progression is, quite literally just calculating this. And because you observe both of these things, right? This is an easy thing to estimate. We literally just substitute in our estimate of the covariance of these two, divide by the covariance of these two, and that's our estimate, our IV estimate of the data. So this is a simple case. It's going to look more complicated in a second, but that's kind of the basic logic. It's consistent, right for beta one, not unbiased, but consistent under these assumptions. And might be n will often be substantially bias in small samples. We

Speaker 1  49:29  
All right, so that's a really simple case, obviously. So we want to develop a more general case. So let's start thinking in terms of multiple regression and work our way up. So we're going to start with a simple version of multiple regression, where we've got one endogenous variable. And so we need to start developing a little bit of notation to try to keep track of everything. And so what I'm going to do is what's often common when thinking about these kind of things, I'm going to use x for our independent variables that are exogenous. Exogenous variables, endogenous variables are going to be indicated by y. So in a case where worried about endogeneity, we've got an endogenous variable on the left hand side, our dependent variable is, by definition, endogenous. And we've also got a predictor that we're worried about is endogenous, indicating that by y2 so in this model, we've got one exogenous predictor and one endogenous. We're just re using a slightly different term notation so we can keep track of what's exogenous, endogenous, and we'll still use Z for our instrument. Okay, so change that takes when we move from bivariate to multiple regression, there is a slight change that it's not conceptually, it's the same, but it's important, right? When we were in the bivariate case, we needed to assume that Z was correlated to death to be a good instrument, it has to be correlated to death. When we move to multiple regression, it's slightly more than that, we need to assume that z is correlated with y, with it, with the endogenous variable, after partialing out the other variables in the model. So our instrument for y2 here needs to be correlated at non zero with y2 after controlling for everything else. So it has to have a non zero partial correlation with the endogenous and so that, as like you know, we're going to take our endogenous regressor and we're going to regress that on all the X variables in the model and our instrument or instruments, and we need that gamma coefficient in that regression. And think about why that's true, right? Remember what we're going to be doing, we're going to be generating predicted values of y2 based on our instrument, and then including those predicted values in the model. Well, if this, if gamma were zero here, that would mean that y2 is being predicted only from the other variables in the model. Then when you try to include it in here, there's gonna be a perfect correspondence between those two, and it's gonna be an unidentified model and unique. It doesn't have unique variance that's unassociated everything else in the model. Words, the model is not identified. You need to be able to predict y2 based on things outside the model. A good instrument needs to have a non zero partial.

Speaker 1  52:59  
Yeah, a push, so x i is so this is sort of the more general form you're going to in the world, well, you're going to be regressing the endogenous predictor, y2 on all the independent variables in the model. In this case, there's only one that's x1 you put an x1 here. Pi is just a coefficient in this regression. This is your instrument. This is the coefficient for your instrument predicting the endogenous independent variable. The assumption that we need to make is that gamma here is not zero, which means that the instrument has an effect on y2 after controlling for the other variables. And we need that because otherwise there the instrument is not even an instrument. It means not predicting y2 at all, independent of these other variables. Of y to just be completely determined by the other variable, model or variable. So the only thing that's changing here, in terms of notation, is that x here, I'm allowing it to be like a vector instead of just one the more general.

Speaker 1  54:33  
Well, if that weren't true, right, then they wouldn't be in the model. So if x1 isn't correlated with y, then it's not even we don't have to assume that that's true. We just need to make sure that if it is true, we control but it doesn't have to be true, like it could be true that pi is zero here and all these variables are independent of y2 that's totally fine. In fact, they're probably better for you in this case, but

Speaker 1  55:12  
yeah, because then predictive value combination of x and a linear combination of x is black plus

Unknown Speaker  55:30  
Okay,

Speaker 1  55:32  
so the upshot here again is just same assumptions, except we just need to add this idea of correlation as being associated with the endogenous progress or above and beyond the other independent variable. Okay, so, so we've been thinking about like special cases. We want a general grid. And the general approach to this is two stage three squares. And so two stage these squares is general in the sense that it allows for IV estimation with multiple regression, with multiple instrumental variables and multiple end document you can have more than one instrument, you can have more than one end document variable, that could get more than one end document variable. But it's the general case. It allows for all those different things. So what is to say to these squares? It's basically exactly what I've just been saying, just expanded, and we're gonna have a slightly different estimation. But the basic idea is the same. We have an endogenous, or more than one endogenous, independent variable, and for each of them, we want to purge those independent variables of the variance that's associated with the error term. So what we're going to do for each of these endogenous independent variables is regress them on all independent variables and all instruments. We're then going to take those predict and we're then going to generate predicted values based on the equation and then include them the predicted values in the model as instruments for the original variable. So for each endogenous regressor in the original model, we regress it on all independent variables and all other exogenous independent variable decision set and all the instruments that we have. We generate predicted values from those first stage regressions and include them as substitute predictors for the original exogenous version. Now the whole idea, again, is that, because we've regressed each endogenous predictor on only exogenous things, those predicted values are now, by definition, exogenous, right? They give you unbiased estimates of the original variable, but ones that are purged of all the variance that's correlated here. If that's true, then, then this procedure will generate consistent estimates in a second stage OLS regression. So once we've included predicted values of all the Add genes, regressors as the new variant, as the substitute variables, we estimate a second stage OLS regression, right using those substitute values, and that's going to give us consistent estimates of the data set. Range what this procedure? So you can do this procedure, and I'll show you in a second, it'll give you the right estimates for data. What it will not give you are the correct standard errors. So you can get consistent estimates of all the betas using this procedure, but it will give you wrong standard errors, and we need to do something different. So let me show you an example, and then we can start with the questions before the end. So I think the these are data that are either in the car data package or data. So you might think that skipping class reduces college GPA, reasonable. But the problem is, is that skipping class is unique to other things, right, like conscientiousness and how motivated for now, let's say we have data set where we've got a ton of different controls, we've got college, GPA, we've got how much you skipped class, but what we don't have are measures of conscientiousness and we don't have measures of motivation. And so we're worried that if we just look at, you know, the correlated, the partial correlation of skipping class and GPA, we're going to end up with a bias estimate that might be due to like, dispositional conjugation. So let's say that that's sort of our problem, and what we need to do is find variables in our data set that are good instruments for skipping class. Skipping classes endogenous. We need good instruments for skipping class. So here we're going to propose a few, I think the ones we're going to use are whether you can walk the class, whether you we whether you have a car, whether you can bike to class and whether you live on campus. So those four variables, the argument would be right, that they increase or decrease the probability of skipping class, but they're unrelated to GPA, except through skipping class, they have no independent effect. Again, quibble and quibble on all these things, right? But that's that would be the argument. So that's what we're going to try to do. So here I've got a model where the first thing where we're going to model just skip, but the first stage regression in two SLS is going to regress the endogenous predictor on all the instruments. So here I've got living on campus, having a car, biking to class, walking to class, and then I've got all the other independent variables that are going to go into the model for GPA. So what class you're in, gender, whether you're first generation, your high school, GPA, a, CT, score, something, whether you agree how many clubs you're in and how much alcohol. So let's say that all these other predictors down here are the are the things we think need to be controlled for in the model, and that we've observed up here are our instruments. We think these are properly excluded from GPA, but are

Unknown Speaker  1:01:42  
going to have an effect on skip.

Speaker 1  1:01:44  
So our first stage regression of two stage least squares is to regress skips on all the instruments and all of the exogenous X variables. So we can do that and see the result we're going to talk about sort of tests for whether your instruments are any good. But at least some of these seem to be pretty good. Biking to class has a substantial negative effect on whether you skip being able to walk to class, substantial negative effect on skipping car and campus. A little bit less once you take it into account by walking. But it seems like we've got at least two instruments here that are decent and then, and that's and again, that after partialing out all of the other expert so these need to have an effect on skipping class after accounting for everything else for them to be good instrument. And that does seem to be true here, but we can. I'll show you a more formal test. Good so far is that. What we're going to do now is just generate predicted values like literally using predict. We're going to do predict on this model. We're going to get predicted values for skipping class based on everything else in that model, and then we're just going to include those. Well, I guess here I'm just pulling it out of the object itself, the fitted values, but here I'm just pulling out the predicted values from this model and including them as a predictor in the second stage equation for GPA. Right now, our dependent variable is GPa. We're using our fitted values as an instrument, fit a value from the first stage equation as an instrument for skipping class, and we're including all the other exogenous controls that we thought were important that appear to that first stage model. When once we estimate this model using OLS, we get a consistent estimator for skipping class on GPA. This, this estimate here is a consistent estimate the effect of skipping class on GPA, and it's interpreted just like any other regression. Again, what it is is that predictor is the fit in values from this first stage, the predicted values based on all and it's exogenous. Why is it exogenous? Because we are generating those predictive values based on only exogenous variables. So by assumption, right? Because these are all exogenous, this has to be exogenous. All of its variance is exogenous.

Speaker 3  1:04:30  
Age. We're assuming that alcohol is exogenous to whether you

Speaker 1  1:04:36  
skip class, all of these are exogenous in the sense that they are not correlated with the error term in the model for GPA. So So endogeneity here means in the model for GPA, which is what we're interested in, they're correlated with the error term. So skipping class is correlated with error term for GPA, because we're worried that conscientiousness is included variable, but we're assuming that that's not true about Yeah, so something totally can quibble with all that stuff, but these variables are exogenous, not in the skip. Well, we are assuming that they're exogenous in this equation too, but the exogenating we're talking about is exogenating in the model.

Speaker 1  1:05:32  
Yeah. So the key, the basic assumptions here right, are all these variables are exogenators of GPA. These variables are properly and they have some non negligible partial correlation with class. That's what makes these instruments predict. S.

Unknown Speaker  1:06:05  
You look like you're asking significance.

Transcribed by https://otter.ai
