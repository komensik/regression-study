Speaker 1  0:00  
Particular GPA, but we're worried that there are other things correlated in skipping class that are really what's doing the work right, like constant and so skipping class is our endogenous y skipping class is this. We have a bunch of other exogenous, independent variables that we think might explain low GPA, we're not worried about those. We're going to assume they're exogenous. We're worried about skipping class, and we need a set of instruments. Those are, again, variables that are properly excluded from the model for GPA. They don't directly predict GPA, but they do strongly predict skipping class. They predict the endogenous independent variable, but they're properly excluded from the model for GPA. And so here's our what we would call our first stage equation, right predicting skipping class from our set of instruments and from our exogenous variables in the model of interest. Once we estimate this model, we can generate predicted values right for the skip variable, and just include those in the model for GPA along with all the other exogenous again, right. Keep separate in your mind the difference between the exogenous predictors in the model of interest for GPA and the instrumental variables which are properly excluded in this model. So in the first stage equation, all of those variables are in there, right, predicting the endogenous IV. But in the model we're actually interested in for GPA, right, we only have the exogenous predictors, the X variables and the fitted values right, the instrumental variables are excluded from this model, and that's that's by assumption. If we do that right, the coefficient on the on the predicted values from the first state equation is our IV estimator for state class. So yes, I'm just showing you here, right, that that's actually what you can do, and you can do that process, but you, as we finished up with last class, you can instead just use IV rig in R, and that'll give you the same exactly what it's doing. And again, what IV rate wants is the dependent variable, the set of exogenous independent variables. And then in between two bars, the endogenous variable, the endogenous independent variable, right? So in this case, we only have one skip, but you could, in principle, have many, as many as you want, and then you have after that second bar, the set of instruments so far.

Speaker 1  2:58  
Okay, so that's where we left off, and what I mentioned last time was that, using this procedure, this two stage procedure, will give you consistent estimates of all the coefficients. So that's fine. What it won't give you, if you, if you estimate the second stage model and just pull out the standard errors, you will get wrong standard errors. The standard errors are incorrect from this procedure, the T tests are incorrect. All that what we actually need to do. And what IV reg does is it did a slightly different sort of one step approach. So when you get IV Reg, when IV reg gives you standard errors, it's using this approach. IV Ray gives you the right stuff because it's not acceptable. What we're doing now is what actually happens. Okay? So despite its name, two stage, least squares, you can actually do it in one step. That's the right way to do it, and that's that'll give you the correct answer. So in order to understand this, though, we need to develop some additional notation. I'm going to use the notation from Hanson's recent metrics textbook, which I find to be rather clear. That's the case. So we're going to preserve this idea of, you know, endogenous variables being y, exogenous variables that are not instruments being x and instruments being Z, the general way to think about it, but it's going to be helpful to make do a little bit more. So y1 is going to be our dependence variable. So it's an endogenous variable, and we're going to call it one for the dependent variable. That's the thing we're trying to explain. We're going to have a matrix x that is going to be a composite of two sub matrices. So we're basically going to take two matrices and put them together into one, and we're going to call that x. We can call these two matrices. You can label these in two different ways. The first way would be to say x1 and x2 but, and that's sort of making clear that these are both independent variable. But the better way to think about it is x1, and y2 because the first portion is going to be the exogenous independent variable, and the second sub matrix is going to be the endogenous so this there's going to be a matrix X that matrix is taking two sub matrices and just putting them together right into one matrix, and the first Part of that is the exogenous predictors, and the second part is the endogenous predictors. So again, we're just putting them together in R you'll see this very clearly. Putting them, you're just adding columns onto the end of it. So again, we're going to start with the exogenous predictors, and then we're going to stack the columns on the end of that that are the endogenous we're also going to have a second Matrix we'll call Z and we can break that into two sub matrices, which we might label z1 and z2 but it'll be helpful instead to label them as x1 and z2 why? Because x1 is again our same set of exogenous predictors, and z2 is the instrument. Is the set of instruments for y2 and so these two are exactly the same. They're repeated in both of these so the exogenous independent variables appear appear in both x and z in the same order. The only difference between these two matrices is that in X, we have the endogenous predictors, and in z we have the instruments.

Speaker 2  6:50  
Yeah. So would that mean, in other words, that you're controlling the

Speaker 1  6:58  
exogenous variables or constant for the exogenous ones you are, yeah, yeah. That's the way that I think, yeah. That's probably the best way. The other way, you know, if you wanted to take it one step further, would just be, you know, the X. You can think of x like the set of independent variables that are predicting the dependent variable. And you think of z as instead of exogenous variables predicting so this is like, these are the set of variables that for the model, for GPA, these are the set of variables for the model.

Speaker 3  7:36  
Yeah, just, I don't the second one, it would be thinking about the set of variables that's predicting the instrumental variables or second one

Speaker 1  7:45  
here. Yeah, this is the set of variables that predict the endogenous independent variable, y2 so we have two state think about it again in like two stages. Conceptually, the first thing we're going to do is predict y2 from the units, and then we're going to use that predictive model to predict the dependent variable y1. For me, the only difference here is that we're going to end up doing this all in one step.

Speaker 1  8:22  
Let's see. Yeah, I'll show you. I'll show you what this looks like more in a second. Given these definitions, and given x and z as defined here, and y, this is the two SLS estimator, and this is what goes into IV rig, if you run IV, Reg, this is what it's doing that's ugly and extremely hard to make sense of, right? I you know it is what it is that the one thing that's interesting is if you have a situation, right? This is the general case, if you have a situation where the number of instruments is equal to the number of endogenous variables. So let's say, for example, we have one endogenous variable skipping class. And let's say we have only one instrument for it, whether you walk to class or not. In that case, we have one instrument for one endogenous variable. In that very special case, this simplifies greatly down to this. And why is that helpful? Well, if you look at this closely, you'll see that it looks it's a isomorphic. It's the same form as the bivariate IV estimator. So remember, the bivariate IV estimator was the covariance of y with the instrument over the covariance of X with the instrument. And this is very similar to that, right? You have a term here that is basically dividing by the covariance of the instrument X, and you have in the numerator the covariance of the instrument and y. So the form ends up being the same when you have this very special case. So if that helps you at all, it does, but this is the general case. What we're interested in here is developing a procedure that can handle any cases we might be interested in which have any number of endogenous variables and any number of instruments. So we want to be able to, you know, if we have 15 endogenous variables and 35 instruments, we want an estimator that can handle that. And this is the general case, that any number of instruments, so whatever, don't, don't memorize that. No need. But that's what it is. But here, to give you a sense of like, what's happening, I think it is helpful to look at this in R. So here I'm just going to build those x and z matrices for our running example, and you can see that it's not quite as complicated as it might seem. So for x, right? I've got a column of ones for the intercept as always. Then I'm just going to put in the columns for the exogenous independent variables. And that's just all the predictors that I'm assuming are exogenous in that model for GPA, belonging to fraternity or sorority, drinking alcohol, mother, collagen, etc. And then. But if you, if you look at this right? It's those variables with the endogenous predictor stacked on the side attached to that matrix. And so that's what I'm going to do. I'm going to put in the column for my endogenous heat converter and stack it right onto the side of that for z. It's the same thing. I'm going to start with those exact same predictors and then just put my instruments on. So that's what I'm doing. I'm taking these exact same independent exogenous predictors and putting them in first in the same order, and then I'm just stacking the four columns for my instruments right onto the end. So that's what x and z are. That's all there. They're not that complicated. And then I'm just going to say y1 is my dependence variable. And then if I very carefully attempt to write this in our language, I will get the exact set of estimates that I would get. And again, the only tricky part is that you have to be very careful to write that correctly, although in most cases, if you tried to write this and you mess something up, you almost surely will not have matrices that can be multi together somehow, because it will be like n by k by n by k or something spit out an error, you'll know you did something in any case, right? Most in almost any case, we never need to do this, but that's what's going on under the and here I'm just showing you that the two step procedure, where we first regress skip on the instruments, and then we use the predicted values in the second stage, gives you the exact same estimate as the one step procedure, using the matrix so they're equivalent in terms of The estimates for the coach,

Unknown Speaker  13:15  
exactly anybody,

Speaker 3  13:21  
just to confirm the I so the end the IV reg function essentially does a different version of this, the same thing. I guess I'm wondering, I may have missed how IV reg and

Speaker 1  13:40  
IV ray does exactly, exactly. Oh, okay, yeah. So there's, you know, it's helpful, I think, to understand why two stage least squares is called two stage least squares, and it's because, you know, you can think of it as conceptually, as doing this kind of two step procedure. And indeed, that will give you the right estimates. What it won't give you is the right standard errors. And so in practice, what we do is this more general approach, and I'll show you how to get the standard errors from this approach. And so IV reg is using this correct and so the standard errors from IV reg also will be giving you the right, yeah, looking at the

Unknown Speaker  14:23  
output itself. So the fact that there's no there's no difference

Unknown Speaker  14:36  
between two numbers, if there were a larger

Speaker 1  14:39  
difference, is that. So these two sets of estimates are just using the two step procedure and the one step, and they're identical, we'll always get the Same answer, so there can't be a difference.

Speaker 1  15:02  
Okay, so what are the properties these squares, it's consistent, not bias, and the finite sample bias can be quite large for small samples, but it is consistent. It's also asymptotically normally distributed. The asymptotic sampling distribution is normal as well. And so we've got to be careful with small samples. But those are, those are sort of our typical large sample. One thing that you need to be aware of and careful about is that when you have weak instruments, which is, unfortunately often the case for social there's at least two problems that you face. The first is probably intuitive, which is that if you have weak instruments, your two SLS estimator will have higher variance. So it'll it'll be you'll get less certain estimates. You'll have higher standard larger standard errors, larger confidence bounds, all else equal weaker instruments mean less mean, more uncertainty in your estimate. And the way to think about a weak instrument is that the correlation between your I should, yeah, I really shouldn't put x there. There the correlation between your instruments and the endogenous variables is too low, so you have bad instruments when your instrumental variables do not do a good job predicting the endogenous variables of interest. So for example, if my if my instrumental variables, campus, car, bike and walk don't predict skip very well, then they're weak instruments. They're weak instruments. I'm going to have higher variance estimates that make sense, right? This is the second problem that you might face is that larger is that your instruments are imperfect, and so ideally, right, you have purely exogenous variation and your endogenous variable, and then, and the sort of, you know, prototype situation of that is an experiment. Why do we run experiments? Well, we're trying to create a perfect instrumental variable, an instrumental variable that is truly exogenous, and we get that by randomly assigning people. You randomly assign someone to a condition, say, getting a drug or a placebo. You know for a fact that all variation in the treatment condition is exogenous. It is in that sense, perfect. In reality, our instruments are rarely perfect, right? And so there might be some correlation of the instrument with the error term. It might be partly endogenous, and therefore not perfect in that case, right? There is asymptotic bias. So if your instrument is not purely exogenous, if it is correlated with the error term to some degree, then two SLS is asymptotically biased. That bias doesn't go away. Sample size goes to infinity. And the larger the correlation of your instruments with the error term, the larger the asymptotic bias. So can we, I mean, I can't characterize the extent of that bias, but the idea would be that you're going to get further and further away in expectation from the true value, even as your sample size goes to infinity, as the correlation between the error term. And so you want, ideally instruments that are not correlated with your error term, if they are correlated with the error term, you want that correlation to be small.

Speaker 2  19:02  
Individual can be doubt ahead

Speaker 1  19:12  
of time. What happens? Well, let me, let me try to answer that, and then see if it helps answer what you're so there's two sort of things that happen when you add additional instrument? Well, maybe, so the more the better the instrument in terms of the shared variance of the endogenous variable, the lower the variance will be in your estimator, right? So as you add instruments, right? Let's say you add instruments from one to infinity as the instruments go number of instruments go to infinity. If we assume that the definition of an instrument is one, that there is some co variance with the endogenous variable, then the variance goes to zero as the number of instruments goes to infinity. So the simple way to put that would be adding instruments reduces the variance. However, adding instruments increases the finite sample bias off. So if you simply just add a ton of new instruments to your model, and they're not very good instruments, you're probably not reducing variance very much, but you're increasing the bias of your that's something to be aware of, right? Just adding instruments for the sake of adding instruments, regardless of how good they're is probably not a good idea, because it increases the finite sample bias interest. That makes sense. I mean, I understand, like, there's proof stuff on the background, like conception, yeah, I think I'm just talking

Speaker 1  20:48  
Yeah, yes. So what matters in the context of two SLS is the partial correlation between an instrument and the endogenous variable, so that doesn't grow. Very good, important point, and that's enough, right? Having an additional instrument that's highly correlated with the endogenous variable is only useful if it's uniquely, additionally correlated with the endogenous variable. So, yeah, the way, the way to think about it with multiple instruments, is regressing the exogenous variable on all the instruments at the same time, and also the exogenous variable through the model and seeing what the partial correlation is above and beyond everything else. And so if there's no partial correlation, it's not actually an instrument, it's just redundant combination of those things, get whatever other questions,

Speaker 4  21:49  
yeah, what you just said about adding more instruments, adding to the bias, that's because of the last bullet, right? Because they will always be already with the error direct to some extent, or, like, if you keep adding new instruments, but they're not necessarily related with the error term, with the bias to increase

Speaker 1  22:12  
this I'm not, I don't feel terribly comfortable with in terms of My understanding. My understanding is that the answer is that, regardless of this right adding, because this is this is about asymptotic bias, and what we're talking about is finite sample bias. So if your instruments are correlated, the error term your estimator is inconsistent. Adding additional instruments, even if they're they're true instruments in the sense of being uncorrelated with the error term, your estimator has finite sample bias. Even if it's consistent, it's still finite sample bias. There's bias with any finite sample, and the degree of that bias increases with an inverse So my understanding is that the answer is yes, even independent of any correlations increasing the number of instruments, finite sample bias in the two SLS estimator. But I can't prove that.

Speaker 1  23:21  
But yeah, it's important to keep those two things separate, right? When we're talking about correlation of the error term, we're talking about asymptotic bias consistency, when we're talking about finite example, bias, we can still have a consistent estimator, and you get a consistent estimator if this correlation is here. But yeah. The larger point is adding additional instruments without any regard to their quality is not a good idea. You want to be concerned with how good they are. And there's another reason for this. These two properties actually interact with each other. So, if you have some correlation between your instruments and the error term such that you have some degree of asymptotic bias, that asymptotic that asymptotic bias will grow. Holding this constant, the asymptotic bias will get larger, the weaker your instruments are, and vice versa. So having weak instruments with some degree of correlation with the error term is even worse than having a correlation with error term and having two these two things are interactive. So another way to put that would be, if you have weak instruments, you're even more concerned about the correlation here return for some fixed amount.

Speaker 1  24:50  
And so one way to think of one thing that you might want to think about, right? It's like, I think a lot of we're often sort of in this way of thinking about OLS, or standard modeling, where we're really worried about the bias from excluded variables, from omitted variables. And so we think, Well, if there's Omitted Variable bias, OLS is bad, get rid of it. Do something else. But it can, you know, it's just another estimator. It's just another estimator with some degree of bias. If your alternative has a lot of bias too, right? You shouldn't just be saying, well, this is gonna this is better because this is bad. You should be thinking like, you know, Is there good reason to think that the bias is lower in my alternative than it isn't original, and that that might not always be true, right? It might be the case if you have really weak instruments and you don't have a good justification for them, that the asymptotic bias is actually smaller though OLS than dose for two SLS. None of this is to say that it's easy to figure that out, but it's good not to forget that fact OLS is just one option, and your alternative options might not be better, Even if OLS is perfect, the alternatives

Unknown Speaker  26:17  
makes questions. I um,

Speaker 1  26:25  
right? Um, so let's talk about the variance of the estimator. So we said that the two step procedure does not give us the right standard errors. And so what are the right standard errors? Um, it doesn't get any any prettier as we move forward. So the variance, co variance matrix for the two SLS estimator, theta hat two SLS is equal to this thing. It has a form that is similar to our OLS estimator, which is sigma squared times X, transpose, X inverse. So it looks kind of like that. These Q, Q, subscript X, Z, here are the definitions of those things. These are co variance matrices, or between x and z of various sorts. I have the code here to show you how to do that if you wanted to do it. But this is getting complicated now, by hand, an IV rig is going to give you the standard errors you want. But having said that, where do those things? They come from? Plugging in our estimates for these things so we can get an estimate of sigma squared, as we normally do, after we run our two SLS to get the residuals, and we calculate our sigma squared path, and we can get estimates of each of these matrices very easily, just using our actual data, X, transpose times z is x, transpose times z. So those things are easy. You can do this if you want to. And then if you just take the square root of the diagonal of that matrix, here's this matrix. If you take the square root of the diagonal of that matrix, you get the standard curve. That's where the standard errors come from. But again, you're going to want, okay, okay, and so you know, if you just summarize an IV rate optic,

Unknown Speaker  28:32  
okay,

Speaker 1  28:35  
so for the for weak instruments, again, the problem is that they both increase variance and potentially amplify the bias of having problematic instruments correlate of the error term. And so we would want some kind of way of thinking about, you know, whether our instruments suffer from this problem. And it's pretty straightforward how to think about this, right? Really, what we're just trying to do is to see if our instruments are predictive of our endogenous variable. If they're strongly predictive, then they're not weak instruments. And so the standard way to do this is to look at that regression of your endogenous variables on your instruments and see what the x is perfect for that regression. And the rough rule of thumb that people use is f is greater than 10, would be reasonable evidence against problem. If you have only one instrument, and you're regressing your endogenous variable on that instrument, you're going to get a T, simplistic. And if you take a square root of 10, you get about 3.2 and that would be the value good rule of thumb for T instead of matters because f is t squared size of the

Speaker 2  29:56  
f statistic, in addition to the potential relationship between the instrument and whatever we're trying to measure, is there anything that you repeat sample size that could factor here is that

Speaker 1  30:17  
it does it sample size And the number of instruments enters into the f statistic through the degrees of freedom. So, or like, it's easy to see in t too, right? So like, for it's going to depend on the degrees of freedom for T, and that's which t distribution you're using, and if you have many, many predictors and very few observations, you're going to have a t distribution with very small degrees of freedom, which has very bad tails, very spread out, in which case your T specifically is going to be smaller for any given predicted any Given relationship. So the answer is roughly Yes, right? In the sense that if you have a lot of independent variables, a lot of instruments and not many observations, that's going to make it harder to get a large F statistic. But in general, I wouldn't think about it that way, sort of the reason, maybe conceptually, the way to think about it right, is that your models, your model for predicting the endogenous variable from the instruments, is always going to improve as you add more instruments. But you want them. You want to be adding instruments that are predictive, not just like random noise, and so that is adjusting? So, yeah, the answer is yes, but I wouldn't think about it that way. I would just think about it as how good are my instruments at predicting the inductance variable and and that's what this look at the r square, that's very similar, and that's another thing to look at. You're explaining a lot of the variance in the dot and variable that at the end of the day that you're trying to generate good predictions, and the higher you know your your explained variance in that I do

Unknown Speaker  32:26  
with the exclusion restriction? Yeah, no, we there's another test that we're going to do for

Speaker 1  32:38  
that. Yeah, no, this is just seeing if your instruments are strong enough predictors of the endogenous variable, worried about it, but they could be extremely endogenous, and This could be true, we'll use it.

Speaker 1  33:01  
So what there's there's two other kind of diagnostic tests that are very common. In fact, when you run IV Reg, you will automatically get when you summarize the object, you'll get a weak instruments test. You'll get those tests, and you'll get the last test that time you're asking about the second test is testing something slightly different. It's called the Hausman test, or a woffman test, and it's a test to see basically whether you need to be using two safe least squares at all. Now, why would you want to do that? I mean, one thing you might ask is like, well, you know, regardless of whether I actually need to use two SLS, why not I just use it? Isn't it always better to be sure that I'm getting good estimates than worry about OLS? And the answer is no, because two SLS is less efficient than because it's less efficient. If OLS is fine to use. You always want to use OLS, right? Because two SLS is going to give you much higher variance, estimates much more uncertainty. And it's not like, you know these cases we talked about in the past where maybe it's only a slight difference in efficiency, like two SLS is going to be much less efficient target. So if you don't need it, you usually don't want to use it. And so this is one way to think about trying to test whether you actually need two SLS, or whether you can go back to and the key question right for whether two SLS needed, whether there's a correlation right between the purportedly endogenous independent variable on the error term, right? So basically, what you're trying to figure out right again, so in our new notation, we've got potentially endogenous predictor trying to explain our dependent variable. And and this is only endogenous to the some excluded thing, some some other thing that we're not including in the model that that it's correlated with both these things. And if that's true, then this is in the error term, and it's correlated with this thing. If it's in the error term, then it's got to be, it's, in a sense, part of this, and also part of and so that's, that's the way we're going to think about trying to test for this. So you might be able to think about how we would do this. What we're essentially going to do is to look at the first state equation, where we predict the potentially endogenous independent variable from all the instruments and all the exogenous variables. Once we do that right, usually what we've been doing is getting the predicted values and then including those in the second stage. But think about what the residuals are. In that first case, the residuals are going to be everything that's in that potentially endogenous variable that is not you know by assumption. And so to the extent that there is a part of this variable that is not only causing that variable but also causing y in our defense variable, then this will be in the error term. So what we're going to do is take the residuals from that first stage and put them into the second stage model and see if they predict. Why they predict? Why? Then what we're saying is that the parts of our potentially endogenous predictor that are not by assumption, exogenous, are predicting the dependent variable, and so they're in the error term. And if they're in the error term, that means that our potentially endogenous variable truly is endogenous. If this residualized version of that y2 does not predict the dependent variable, then we can be more confident that it's truly that it's exogenous, and we can use so again, what are we doing if we were going to look at the first stage and we're going to extract from our potentially endogenous variable in our running example, this is skipping class. We're going to predict that from all of our exogenous and instrumental variables and take the residuals. The residuals in that first equation are all the parts of that skipping class variable that are potentially endogenous. It's everything that causes skipping class that is not part of our instrumental variable. Now the question is, well, is that stuff that's left over correlated to the dependent variable? If that stuff that's left over is correlated to the dependent variable, then it is. What we're actually saying is that it's in the error term, and so that variable skip is truly in value. And if that's the case, then we do want to use 2x plus excellent, difficult logic here that kind of makes sense conceptually. And so the key test, the Wu Houseman test, is going to be a t test on the coefficient for the first stage residuals in the second stage model. That's, that's what's going on. That's what IV rig is going to tell you. You're not actually gonna have to do this by hand, but that's what and again, the idea is, once we've gotten rid of any variance in y2 that's, that's due to our exogenous variables and instrumental variables. Is there anything left over that's also correlated with y1 if that's true, then that would be a case where that variable is truly okay.

Speaker 4  39:20  
That's one question. What is the like? How do we define like correlated? Like, whether the residual correlated with the dependent variable? And yet, because I can imagine that either it's like a very small effect, or like not significant, like, how? What is the benchmark? Basically this test field.

Speaker 1  39:43  
So the benchmark, in the case of the way that these tests are typically executed, is a t test on that coefficient in the second stage. And so as you'll see in a second, it's going to be just p value and a t statistic now, and you're going to see this in the example I'll give you, you do want to be careful with this, right? Because there's a sense that, you know, this is a case of one of those cases where there's a sense in which you want the null to be true, and when you want the null to be true, usually we're worried about, you know, false positives, and so we have this conservative, you know, p equals point of five or less, criterion for saying something that's significant. But in this case, you might think we want to be actually more liberal, because we were especially worried about rejecting the null, right? And so if we want the null to be true, you might be worried like, like, if the p value is point of seven, everything's fine. Well, you know, not really, probably it's very close to being significant. So are you really that confident?

Speaker 4  40:49  
So the magnitude of the coefficient wouldn't matter here. Let's say that's, it's significant, but it's, let's say it's significant, but the effect is, like, you know, substantively, very small.

Speaker 1  40:59  
Yeah, so that's another, yeah. That's definitely another thing to think about that's going to depend, you know, like standard sample size. So if you have a really large sample size, it might be easy to reject this null, but it might be a very small that, in which case,

Speaker 2  41:18  
in this context, would be the amount of like motivation that would explain the GPA, right, yeah, that was the initial endogenous,

Speaker 1  41:35  
yeah, potentially, right. That would be our the way we were conceptually thinking about it. But it could be anything, you know, it could be things that we had thought of and things we didn't think of as well. It could be anything that's anything that's in skipped, that is not due to our others. Could be anything from there because we're, you know, it's probably worth just going back to the i

Speaker 1  42:04  
Uh, right? So here's the first stage equation, right? We're regressing skips on our instruments and all the other what we're doing for this test is taking the residuals from this model. And so that's just anything that's in skip. That's not something here. So we think, right, it's definitely things like conscientiousness that we're worried about, but it's also potentially anything else we hadn't thought of. And so it could be, there could be other things that are also causing endogeneity that we didn't think about. It

Unknown Speaker  42:38  
residual actually,

Speaker 1  42:44  
yeah, we wouldn't know what it meant, but we would know that we need to use SLS to get rid of it. And so one of the nice things about two SLS, when you have good instruments that it's it's like an experiment. It not only controls for all the things that you can think of, it controls for all the things you can't think of as well, right? Because if your instruments are truly exogenous, it's like randomly assigning people to conditions. And so you don't even need to know what, what the threatening omitted variables are, because you've got a rant, you've got effectively random like experiments are great because you don't even have to think of all random assignment

Speaker 1  43:35  
control, and maybe that's making worth making explicit again, right, when we're coming up with instrument is coming up with variables that we're trying to use to control for the omitted variable, right? Not trying to think of instruments that are proxies for conscientious proxy variable models. We're trying to come up with variables that are strong. Variables that are strong and poorly Omni in instrumental variables we don't hit variables or variable r. What we want are exogenous predictors that predict the endogenous we just want things that are really strongly predictive of skipping class, but are properly excluded from GPA model. We're not looking for predictors that are strongly correlated. In fact, you don't want that not correlate

Speaker 1  44:40  
to the error. And so the last test is, is what Tanya was asking about before, which is our good instruments in the sense of being exogenous in the model of interest, right? So we want, we want our instruments to be strong predictors of that variable, but we also want them to be properly excluded from the from that final model, that GPA model, and to say, properly excluded, are they? Are they endogenous or not? Are they correlated with the error? And so there's a test called the Sargon test that can help us to understand this, but it is only usable in the case where you have what's called an over identified model, or, in other words, where you have more instruments than the number of endogenous variables. If you have one endogenous variable, like in our example, skip you need at least two instruments, and we have four in our example. So we have an over identified model. We have more instruments than the number of endogenous variables. The only time you can do a Sargon test is if you have that kind of over identification. If you have two endogenous variables, you need at least three instruments or indulgence variables at least five, if you have what's called a just identified model, you have a number of instruments equal to the number of endogenous variables. You cannot run a target test. Reason for this is that you know this isn't how it works in practice, but conceptually, what a Sargon test is doing is it's saying that if your instruments are truly good instruments, then it shouldn't, you know, asymptotically, it doesn't matter which instrument you use. You could use instrument one and you could use instrument, you know, without instrument two, or you could use instrument two without instrument one, and in both those cases, you would end up with an asymptotically equivalent estimator. And so what a Sarg test is essentially doing is trying to see whether that is actually a good assumption, not a good assumption. If one of your variables, or more of your instrumental variables is endogenous, then they're not asymptotically equivalent, and you should get substantially different estimates depending on which if they're good instruments, you should get something very similar, regardless of words. That's why you need more instruments than the number of adoptions variables, because you can't do that separately unless you have enough. Um, so what are we going to do? We are going to take our two SLS residuals, so our two stage least squares residuals from our actual two stage least squares model, and we're going to regress that those on all those stage one variables, both our exogenous independence variables, and our instruments. And then we're going to calculate sample size times r squared, because this ends up being distributed chi square, with degrees of freedom equal to the number of extra instruments. So in our case, we have one endogenous variable, four instruments. So Q is equal to four minus one, and so n times R squared is distributed pi squared on Q, degrees of freedom. In our case, three. If we can reject the null here, right? Then we're worried about endogenous we're worried about the endogeneity occurring. So this is another case we don't want our instruments to be endogenous, so we're hoping not to reject reject this null. And so if we do reject this null, there's evidence that at least one of our endogenous, at least one of our instruments is a bad instrument. It's endogenous. Now it doesn't tell you which one, and so that's probably that's hard to deal with. One thing you can do, and this is, you know, this isn't fantastic, but it's something right you can compare to us to SLS estimates across different model specifications, where you remove one instrument at a time, and try to see if removing one substantially changes the estimates relative to the other possibilities I could remove, like if I have, you know, walking, biking to campus, having a car, living on campus, and remove one of those each time, and use the other three to make to SLS and see if I get substantially different estimates across those frequent estimations. That's not perfect, but it's something

Speaker 2  49:30  
for that in comparing two or three treatments for one model, then if I guess I'm just thinking like, if you were trying to isolate one individual instrument, and we have to make an assumption that there was absolutely no relationship between instruments themselves, because if You took out one another, would it change the I want to

Unknown Speaker  50:03  
say, No, I need

Speaker 1  50:20  
to think about that. I'm actually not about that. I'm actually not confident. Yeah, I want to say no. It wouldn't matter. Okay, so these are hard to record for sure. In practice, what are you going to do? You're probably going to be using IV reg. So here's an example. Here's our example. Now I'm not taking anything out, right? So I called IV reg with GPA as the defense. All my exogenous predictors in between the two bars my endogenous variable, in this case, we only have one, but there could be more, and I've got four instruments. So this is just the example, but now I'm just going to summarize that IV ray object and show you what you get out overall. And here's the table. See that we're getting the exact same estimate we've been getting for our the coefficient for our endogenous predictor skip and again, that's because all the different ways we've done it are exactly the same for this estimate. But now we're getting standard errors that are appropriate. So IV rate is giving us the right standard inference, giving us the right P value, it's giving us the right hypothesis test. So if you use IV rig, you're getting what you want. And IV rig will also give you, by default, these three diagnostic tests that I just talked about. So here's the weak instrument test. Our rule of thumb, roughly, is that. So this is an ACT test, and so we've got a F statistic of about five. That's not 10. So you know, if you use that rule, even though it's highly significant, you might be worried that your instruments are somewhat weak in practice. I mean, I you know, instrumental variables regression is less popular than it used to be, but it's very hard to find new instruments. So not entirely clear what rule of thumb to use, but that standard criterion of 10 our instruments would not meet that. Here's the Wu Hausman test, and this is a test for whether we need to use two SLS or whether OLS is okay. In other words, it's a test for whether this variable skipped actually endogenous or not. So again, what we're we're doing with this test is taking the residuals from the ercage equation and seeing if they predict the Depend variable in the second stage. And that's a hypothesis test on that variable that residuals variable whether it predicts the defense variable, GPA. And here, as we were saying before her, we're failing to reject the null with a P value of point two, two. We want to reject. Well, in this case, if we reject the null, then we say that OLS is problematic, and we move to two SLS. So rejecting the house, the house and pass is equivalent to saying we have evidence in favor of skipped being endogenous. So this is testing whether our we have evidence that our potentially endogenous variable, in this case, skipped, is truly endogenous, and therefore we need to use two safety squares. Failing to reject the null like we do here, is telling us that we don't have strong evidence that skip is truly endogenous, and therefore maybe we can use OLS instead of use page of the squares, as we were talking about before. How confident that P value of point two two is going to be for you is maybe a matter of case I would not feel terribly confident about that. Failing to reject the null with

Speaker 1  54:33  
Sargon, right is telling you if you reject the null for Sargon, which we do not do here, a rejection of the null to the starting test is evidence that at least one of your instrumental variables is endogenous. Therefore families reject the null suggest that your instruments are okay, not necessarily strong instruments, but not endogenous. So these two bottom right are telling you how good your instruments are. Are they strongly predictive and are they endogenous? You want them to be strongly predictive. You want this to be very significant, and you want this to be very the middle one is telling me is answering the question, should I use OLS or two SLS if you fail to reject the null, saying OLS is fine. If you reject the null, it's saying two SLS is needed. But again, with a grain of salt. So having said all that, like, what do you what ends up happening in practice? In the old days, people would say things like, you know, the potential endogeneity, so I use two SLS, and then they wouldn't tell you, and everyone would be like, Oh, solve problems. That's not acceptable. You need to justify what you're doing. And because it's so hard to justify what you're doing, in almost every case that you would do something like this, you would end up reporting both the two SLS estimates side by side. So in your assignment, your click on assignment for this week, you're going to be doing problems using data from charia Blackwell and Sam's book deep roots on the role of slavery in the South and contemporary political attitudes, and they estimate to understand in counties where there was a higher proportion of the population enslaved In 1860 our political attitudes in us is different based on how much, how important slavery was to the economy in those local areas in 1860 they use OLS, where they just use proportion enslaved in 1860 as the key variable, and they predict contemporary attitudes from that. But you might be worried that, you know, there's, there was some kind of selection into counties that were the types of people that moved into counties with higher slavery percentages in 1860 were different in some way, or there's something fundamentally, you know, different about those areas that makes this a problematic conclusion, and so they also do a two stage least squares analysis, where they instrument proportion slave, 1860 with cotton suitability. They have a variable they call cotton suitability, and it's basically a sort of a an environmental variable that they are exogenous, because you can't have anything to do with why people move there. It's geological, and so you're gonna and in their book, all this stuff is very long way of saying in their book, right? They roll OLS n to SLS s in that second pair of compare them and try to show that the evidence same, regardless of what they use. And you're going to go through and do that. So that is the most common way to do things, and most of the time the reason is because very hard to justify to SLS. In social science, it's super hard to find good instruments,

Unknown Speaker  58:31  
great questions.

Speaker 1  58:36  
To the extent you end up doing this, you're just going to have to go back and try to remember, go back to the slides, or go back to the textbook, or at least, I mean, I have a particularly bad memory, so I can never remember.

Speaker 1  58:55  
So one more thing to talk about with two SLS, and I'm gonna do this pretty quickly, because it's not worth your time here we've assumed homoscedasticity so far. Obviously that's often wrong. So the question then becomes, what happens when you have potentially heteroscedasticity or clustered standard errors? And the answer is that it gets even more disgusting in terms of estimating the variance co variance matrix. Now this is what it is, what it is, and that is very hard to understand. And so you can do it, but don't do it instead. Use the sandwich package, and you can use it in basic the same way you do for OLS. If you've estimated the IV reg model. You can specify, you know, variance CO, variance matrix, put in your summary. And so here are just the HC three errors. But if you want to, you know, do it directly here. Again, it's just the exact same thing for OLS. You can choose HC zero, HC three, HC one, whatever it is. You're just doing it the exact same way that you've been doing it. So iteration. You're just using sandwich. You can also do this for clustered standard errors as well. Works the same way.

Speaker 1  1:00:28  
Okay? So, I mean, I've pretty much already said this, I guess, but it's worth, maybe worth just being very close when we're in the context of two stage least squares, we're worried about what's called identification. And identification, in general terms, just means whether there's a unique set of estimates for the thing we're trying to estimate, not worth getting into right now. But the basic idea of identification is, can you get unique estimate. And in order to do that, you have to have a full rank matrix we talked about, into SLS. There are conditions under which that's the case versus not. We've already gone through them implicitly, but let's just go through them explicitly. Again, a necessary condition for having an identified two stage least squares model. It's necessary, not sufficient, but necessary is what's often called the order condition. And the order condition is that you have at least as many instruments as endogenous variable. So if you have one endogenous variable, like in our example, skip you need at least one or more. If you have two endogenous variables, you need at least two instruments and so on. That's the order of condition you need greater than or equal to endogenous variable. You need instruments equal to or greater than the number of endogenous variable that is necessary but not sufficient. The sufficient condition is that you need at least as many instrumental variables that provide unique information about the endogenous variable. So this is what we were talking about, about partial correlation. It's not enough to just throw in four instruments for for two endogenous variables, it has to be the case that you have at least two variables worth of unique information predicting that endogenous variable. So if only one of your instruments for two endogenous variables has unique predictive power, right, and the others are just surface, then the model is not identified. So even though you're meeting the order condition, you're not meeting the more important sufficient condition. And that second, the sufficient, necessary and sufficient is called the rank condition. And it's called the rank condition that it has to do with the rank of the co variance matrix between the instruments and between z and f, basically, and the formal statement is just that the rank has to be k, and that's basically what I just said, right? If this is true, then you have enough unique information. All this is sort of the formal statement of it. What you want to remember in your head, right? Is I need as many instruments as endogenous variables. That's number one. If you don't have that and everything is glasses, right? You have to have that. You need as many instruments as endogenous variables. But then you also need to make sure that you feel confident that you have enough issues

Unknown Speaker  1:03:47  
from those instruments.

Speaker 1  1:03:49  
You have instruments that are providing unique information,

Speaker 1  1:04:00  
a couple other that I've probably thrown around a bit that maybe I haven't defined yet, we say a model is over identified when we have more instrumental variables providing unique information, and in that case you can run fast. We say a model is just identified when we have a number of instrumental variables that provide unique information that's equal to the number just identified, when any instruments equal to endogenous is over identified, for a just identified model, we cannot feel confident that our instruments are

Unknown Speaker  1:04:43  
truly

Speaker 1  1:04:47  
this kind of language of identification comes up a lot again in other contexts, like measurement models,

Speaker 1  1:04:58  
a caution. So this is kind of a technical point, but you might, you might be wondering about bootstrapping in the context of instrumental variable regression, it turns out that, because of the problematic finite sample problem class, it turns out that the number of finite moments, so remember, what moments are the distribution, the expected value, the variance, skewness, kurtosis, etc,

Unknown Speaker  1:05:26  
the number

Unknown Speaker  1:05:29  
of the two SLS estimator is

Speaker 1  1:05:31  
equal to the number of over identifying restrictions, or in other words, equal to the difference between the number of instruments that provide unique information And the number of dodging therapy. So what that means is that in a just identified model, there is no finite expected value of the two XLS estimator. If you have one extra instrumental variable, there's a finite expected value, but no finite variance of that estimator. So that's not a problem for asymptotic properties, which is what we're relying on in everything we've done so far.

Unknown Speaker  1:06:06  
It's a huge problem.

Speaker 1  1:06:09  
Boot scrapping is attempting to estimate the finite sample. Sampling, that's what it does. That's why we like it, because that's what we're trying to do. But if you have a just identified model or only one extra instrument, there is no fine. Doesn't exist. Yeah, it doesn't exist. And so is trying to approximate something that is infinite, and it'll just fail. It'll be very problematic. So you can't use bootstrapping unless you have at least 2x frame or your number of uniquely predictive instruments has to be at least two greater than the number of pathogenous variables where bootstrapping will be very problematic. This seems to be a point that most people don't know, and so I think it's actually quite common to us in situations where it's inappropriate.

Speaker 1  1:07:17  
One last topic and the last way that we can get into negative we haven't really talked about is measurement error. And so it's worth just unpacking quickly what that is, because it has some unique things that we found. Um, so let's what is measurement, and we're going to sort of take what's called the classical test theory perspective. Here, for classical true score theory, we're going to say that a measured variable, there's something we measure like is equal to the true value of that variable plus some random error. So when we measure height with a ruler, we have a measurement that is equal to the expected value, the true value, plus some totally random deviation from true value due to the imprecision of the measurement. So we want to know what the consequences of this are, and we want to know what the consequences are depending on whether the number is in our dependent variable. Whether it's in our it's going to be different. So the case that's less concerning is when it's in the dependent variable. So let's take a look at why that is. So here we've got our depend. Our measured dependent, by measure is equal to the true value of y plus error. Now let's think about what we do when we regress our measured Y on our independent variables. What model are we estimating?

Unknown Speaker  1:08:53  
Well, on

Speaker 1  1:08:55  
X, beta plus U, the error term for the regression, but measured y is equal to you.

Unknown Speaker  1:09:14  
Switch the true value. Okay, I'm

Speaker 1  1:09:17  
just gonna We're basically out of time. Anyway, I'm gonna fix these slides make sure I didn't make any didn't make any other mistakes, and we'll just finish this up on

Unknown Speaker  1:09:27  
Thursday. Yeah,

Speaker 1  1:09:32  
yes, exactly. And we're gonna This shouldn't take too much longer, and then we're gonna go right into Okay, so

